import logging
import json
from typing import Dict, Any, List
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from app.agent_module.state import AgentState
from app.services.rag_service import rag_service
from app.core.llm import llm

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# --- Helper Prompts ---

GRADER_PROMPT = """You are a grader assessing relevance of a retrieved document to a user question. 
Here is the retrieved document:
{context}

Here is the user question: 
{question}

If the document contains keyword(s) or semantic meaning useful to answer the question, assess it as relevant.
Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question."""

REWRITE_PROMPT = """You a question re-writer that converts an input question to a better version that is optimized 
for vectorstore retrieval. Look at the initial and formulate an improved question.
Input Question: {question}
Output with only the improved question and nothing else."""

DIAGNOSIS_PROMPT = """You are an expert telecom network engineer.
Based on the [Context Documents] below, analyze the [Anomaly] and provide a Root Cause and Action Plan.

[Context Documents]
{context}

[Anomaly]
- Title: {title}
- Description: {description}
- Related KPIs: {related_kpis}

[Instructions]
1. Summarize the 'Root Cause' in one sentence.
2. Provide a step-by-step 'Action Plan'.
3. If the context doesn't help, say "No specific manual found" and suggest general checks.

Format: JSON
{{
    "root_cause": "...",
    "action_plan": "..."
}}
"""

# --- Nodes ---

def start_rag_process(state: AgentState) -> Dict[str, Any]:
    """
    [Node] RAG í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (Start RAG)
    ë¶„ì„ ë‹¨ê³„ì—ì„œ ê°ì§€ëœ ì´ìƒ ì§•í›„(Anomaly)ë¥¼ RAG íì— ì ì¬í•©ë‹ˆë‹¤.
    
    Args:
        state (AgentState): í˜„ì¬ ìƒíƒœ
        
    Returns:
        Dict: rag_queue ì´ˆê¸°í™” ë° ë¡œê·¸
    """
    logger.info("ğŸš€ [Node: Start RAG] ì‹œì‘")
    anomalies = state.get("anomalies", [])
    
    # ì‹¤ì œ ì´ìƒ ì§•í›„ë§Œ í•„í„°ë§ (is_anomaly=True)
    real_anomalies = [a for a in anomalies if a.get("is_anomaly")]
    
    if not real_anomalies:
        logger.info("âœ… ë¶„ì„í•  ì´ìƒ ì§•í›„ê°€ ì—†ìŠµë‹ˆë‹¤. RAGë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {"next_step": "end", "logs": ["âœ… No anomalies to analyze."]}
        
    logger.info(f"ğŸ“‹ RAG ë¶„ì„ í ìƒì„±: ì´ {len(real_anomalies)} ê±´")
    return {
        "rag_queue": real_anomalies,
        "rag_completed_anomalies": [], # ì™„ë£Œëœ í•­ëª© ì €ì¥ìš©
        "logs": [f"ğŸš€ Starting RAG analysis for {len(real_anomalies)} items."]
    }

def pop_from_rag_queue(state: AgentState) -> Dict[str, Any]:
    """
    [Node] íì—ì„œ í•­ëª© ì¶”ì¶œ (Pop from Queue)
    RAG íì—ì„œ ë‹¤ìŒ ë¶„ì„ ëŒ€ìƒì„ êº¼ë‚´ì–´ 'current_rag_anomaly'ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    ë¶„ì„ì„ ìœ„í•œ ì´ˆê¸° ê²€ìƒ‰ ì¿¼ë¦¬ë„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    queue = state.get("rag_queue", [])
    
    if not queue:
        logger.info("ğŸ RAG í ì†Œì§„. ì²˜ë¦¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return {"current_rag_anomaly": None} # Queue finished
    
    current = queue[0]
    remaining = queue[1:]
    
    # ì´ˆê¸° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ì œëª© + ì„¤ëª… ì¡°í•©)
    query = f"{current['title']} {current['description']}"
    
    logger.info(f"ğŸ‘‰ [í•­ëª© ì²˜ë¦¬ ì‹œì‘] {current['title']}")
    logger.debug(f"ğŸ” ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    
    return {
        "rag_queue": remaining,
        "current_rag_anomaly": current,
        "search_query": query,
        "rag_retry_count": 0,
        "logs": [f"ğŸ” Analyzing: {current['title']}"]
    }

def retrieve_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node] ë¬¸ì„œ ê²€ìƒ‰ (Retrieve)
    Vector DBë¥¼ í†µí•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    query = state["search_query"]
    logger.info(f"ğŸ“š [Retrieve] ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘: '{query}'")
    
    try:
        docs = rag_service.search(query, k=3)
        logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(docs)} ê°œì˜ ë¬¸ì„œ ë°œê²¬")
    except Exception as e:
        logger.error(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        docs = []

    return {
        "retrieved_docs": docs,
        "logs": [f"ğŸ“š Retrieved {len(docs)} documents."]
    }

def grade_documents_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node] ë¬¸ì„œ í‰ê°€ (Grade)
    ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ LLMì„ í†µí•´ í‰ê°€í•©ë‹ˆë‹¤.
    """
    logger.info("ğŸ§ [Grade] ë¬¸ì„œ ì í•©ì„± í‰ê°€ ì‹œì‘")
    docs = state.get("retrieved_docs", [])
    query = state["search_query"]
    
    if not docs:
        logger.warning("âš ï¸ í‰ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {"is_relevant": False, "logs": ["âš ï¸ No documents found."]}
        
    # ë¬¸ì„œ ë‚´ìš© ê²°í•© (Simplified Bulk Grading)
    context = "\n\n".join(docs)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", GRADER_PROMPT),
        ("human", "User question: {question}\n\nContext: {context}")
    ])
    
    try:
        chain = prompt | llm
        response = chain.invoke({"question": query, "context": context})
        score = response.content.lower().strip()
        is_relevant = "yes" in score
        
        logger.info(f"ğŸ“ í‰ê°€ ê²°ê³¼: {'ì í•©(Relevant)' if is_relevant else 'ë¶€ì í•©(Not Relevant)'} (Score: {score})")
        
        return {
            "is_relevant": is_relevant,
            "logs": [f"ğŸ§ Relevance Check: {is_relevant}"]
        }
    except Exception as e:
        logger.error(f"âŒ ë¬¸ì„œ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ë¶€ì í•© ì²˜ë¦¬ ë˜ëŠ” ì¬ì‹œë„ ë¡œì§ í•„ìš” (ì—¬ê¸°ì„  False)
        return {"is_relevant": False, "logs": [f"âŒ Grading Error: {str(e)}"]}

def rewrite_query_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node] ì¿¼ë¦¬ ì¬ì‘ì„± (Rewrite)
    ë¬¸ì„œê°€ ë¶€ì í•©í•  ê²½ìš°, ê²€ìƒ‰ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤.
    """
    current_query = state["search_query"]
    retry_count = state.get("rag_retry_count", 0) + 1
    
    logger.info(f"ğŸ”„ [Rewrite] ì¿¼ë¦¬ ì¬ì‘ì„± ì‹œë„ ({retry_count}íšŒì°¨)")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", REWRITE_PROMPT),
        ("human", "Input Question: {question}")
    ])
    
    try:
        chain = prompt | llm
        response = chain.invoke({"question": current_query})
        new_query = response.content.strip()
        
        logger.info(f"âœ¨ ìƒˆë¡œìš´ ì¿¼ë¦¬ ìƒì„±: '{new_query}'")
        
        return {
            "search_query": new_query,
            "rag_retry_count": retry_count,
            "logs": [f"ğŸ”„ Rewriting Query ({retry_count}/3): {new_query}"]
        }
    except Exception as e:
        logger.error(f"âŒ ì¿¼ë¦¬ ì¬ì‘ì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return {
            "search_query": current_query, # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ì¿¼ë¦¬ ìœ ì§€
            "rag_retry_count": retry_count,
            "logs": [f"âŒ Rewrite Failed: {str(e)}"]
        }

def generate_diagnosis_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node] ì§„ë‹¨ ìƒì„± (Generate Diagnosis)
    ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ì¸(Root Cause)ê³¼ ì¡°ì¹˜ ë°©ì•ˆ(Action Plan)ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    logger.info("ğŸ’¡ [Generate] ìµœì¢… ì§„ë‹¨ ìƒì„± ì‹œì‘")
    anomaly = state["current_rag_anomaly"]
    docs = state.get("retrieved_docs", [])
    context = "\n\n".join(docs) if docs else "No specific documents found."
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a helpful assistant."), # Generic system msg prepended
        ("human", DIAGNOSIS_PROMPT)
    ])
    
    chain = prompt | llm
    try:
        response = chain.invoke({
            "context": context,
            "title": anomaly["title"],
            "description": anomaly["description"],
            "related_kpis": str(anomaly["related_kpis"])
        })
        
        # Parse JSON
        content = response.content.replace("```json", "").replace("```", "").strip()
        result = json.loads(content)
        
        # Update Anomaly
        anomaly["root_cause"] = result.get("root_cause", "Analysis Failed")
        anomaly["action_plan"] = result.get("action_plan", "Please check manually.")
        
        logger.info(f"âœ… ì§„ë‹¨ ìƒì„± ì™„ë£Œ: {anomaly['root_cause']}")
        
    except Exception as e:
        logger.error(f"âŒ ì§„ë‹¨ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        anomaly["root_cause"] = "Analysis Error"
        anomaly["action_plan"] = f"Failed to generate analysis: {str(e)}"

    # We return the UPDATED anomaly in a list. 
    return {
        "current_rag_anomaly": None, # Finished processing
        "rag_completed_anomalies": [anomaly], 
        "logs": ["âœ… Diagnosis Generated."]
    }

def finalize_rag_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node] RAG ì¢…ë£Œ ì²˜ë¦¬ (Finalize)
    RAG ê³¼ì •ì„ í†µí•´ ë³´ê°•ëœ ì´ìƒ ì§•í›„ ë¦¬ìŠ¤íŠ¸ë¥¼ ìµœì¢… ìƒíƒœì— ë°˜ì˜í•©ë‹ˆë‹¤.
    """
    logger.info("ğŸ [Node: Finalize] RAG ë¶„ì„ ì¢…ë£Œ")
    enriched = state.get("rag_completed_anomalies", [])
    
    # (Optional) ê¸°ì¡´ state['anomalies']ì™€ ë³‘í•© ë¡œì§ì´ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ìˆ˜í–‰
    
    return {
        "anomalies": enriched,
        "logs": ["ğŸ RAG Analysis Completed."]
    }

