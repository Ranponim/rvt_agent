import json
from datetime import datetime
from typing import Dict, Any, List
import logging
import traceback

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

from app.agent_module.state import AgentState, ValidationResult
from app.models.kpi_data import PMData
from app.core.config import settings
from app.core.llm import llm

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

def parse_data_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node 1] ë°ì´í„° íŒŒì‹± (Parse Data)
    ì…ë ¥ëœ JSON ë°ì´í„°ë¥¼ Pydantic ëª¨ë¸(PMData)ë¡œ ë³€í™˜í•˜ì—¬ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        state (AgentState): í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ
        
    Returns:
        Dict: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (parsed_data, logs)
    """
    logger.info("ğŸ“¡ [Node: Parse Data] ì‹œì‘")
    parsed = None
    
    raw_data = state.get("current_data_15min")
    if raw_data:
        try:
            # ë”•ì…”ë„ˆë¦¬ì—ì„œ PMData ê°ì²´ ìƒì„± (Validation ìˆ˜í–‰)
            parsed = PMData(**raw_data)
            logger.info(f"âœ… ë°ì´í„° íŒŒì‹± ì„±ê³µ. KPI ìˆ˜: {len(parsed.kpi)}")
            return {"parsed_data": parsed, "logs": ["âœ… ë°ì´í„° íŒŒì‹± ì„±ê³µ."]}
        except Exception as e:
            error_msg = f"âŒ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {"logs": [error_msg]}
    
    logger.warning("âš ï¸ íŒŒì‹±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (Missing current_data_15min)")
    return {"logs": ["âš ï¸ íŒŒì‹±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]}


def analyze_kpi_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node 2] KPI ë¶„ì„ (Analyze KPI)
    Choi ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ KPI ë°ì´í„°ì˜ ì´ìƒ ì§•í›„ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
    L2/L3 ë¶„ì„ ë¡œì§ì„ í†µí•©í•˜ì—¬ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        state (AgentState): íŒŒì‹±ëœ ë°ì´í„°ê°€ í¬í•¨ëœ ìƒíƒœ
        
    Returns:
        Dict: ê°ì§€ëœ ì´ìƒ ì§•í›„ ë¦¬ìŠ¤íŠ¸ (anomalies)
    """
    logger.info("ğŸ” [Node: Analyze KPI] ì‹œì‘")
    
    # ìƒíƒœ í‚¤ ë””ë²„ê¹… (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)
    # logger.debug(f"DEBUG_NODE: keys in state: {list(state.keys())}")
    
    data: PMData = state.get("parsed_data")
    if not data:
        logger.error("ğŸ›‘ [Analyze KPI] parsed_dataê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return {"next_step": "end", "logs": ["ğŸ›‘ ë°ì´í„° ëˆ„ë½ ë¶„ì„ ì¤‘ë‹¨"]}

    anomalies: List[ValidationResult] = []
    
    # --- Choi Algorithm Integration ---
    from app.services.choi_strategy_factory import get_choi_strategy_factory
    from app.models.judgement import PegSampleSeries, FilteringResult, JudgementType
    
    try:
        logger.info("ğŸ› ï¸ Choi ì•Œê³ ë¦¬ì¦˜ ì „ëµ íŒ©í† ë¦¬ ì´ˆê¸°í™” ì¤‘...")
        factory = get_choi_strategy_factory()
        judgement_strategy = factory.create_judgement_strategy()
        choi_config = factory._get_judgement_config_dict()
        
        # 1. ë°ì´í„° ì¤€ë¹„ (Convert Agent State to Choi Input)
        filtered_data = {}
        
        # Pre Data (Baseline - 1hour avg)
        pre_map = {}
        if state.get("current_data_1hour"):
            pre_pm = PMData(**state["current_data_1hour"])
            for item in pre_pm.kpi:
                pre_map[item.peg_name.split("(")[0]] = item.avg
            logger.debug(f"ğŸ“Š Pre-Data ë¡œë“œ ì™„ë£Œ: {len(pre_map)} í•­ëª©")
                
        # Post Data (Current)
        post_map = {}
        for item in data.kpi:
             post_map[item.peg_name.split("(")[0]] = item.avg
        logger.debug(f"ğŸ“Š Post-Data ë¡œë“œ ì™„ë£Œ: {len(post_map)} í•­ëª©")
             
        # Configì— ì •ì˜ëœ KPIë§Œ ì¶”ì¶œí•˜ì—¬ Series ìƒì„±
        all_topics = choi_config.get("kpi_definitions", {})
        processed_kpis = set()
        
        for topic, definition in all_topics.items():
            # Main KPI ì¶”ì¶œ
            main_kpi = definition.get("main")
            if main_kpi and main_kpi not in processed_kpis:
                filtered_data[main_kpi] = [PegSampleSeries(
                    peg_name=main_kpi,
                    cell_id=data.cell_id if hasattr(data, 'cell_id') else "unknown",
                    pre_samples=[pre_map.get(main_kpi, 0.0)] if main_kpi in pre_map else [],
                    post_samples=[post_map.get(main_kpi, 0.0)] if main_kpi in post_map else [],
                    unit="unit"
                )]
                processed_kpis.add(main_kpi)
                
            # Sub KPIs ì¶”ì¶œ
            for sub in definition.get("subs", []):
                if sub not in processed_kpis:
                    filtered_data[sub] = [PegSampleSeries(
                        peg_name=sub,
                        cell_id=data.cell_id if hasattr(data, 'cell_id') else "unknown",
                        pre_samples=[pre_map.get(sub, 0.0)] if sub in pre_map else [],
                        post_samples=[post_map.get(sub, 0.0)] if sub in post_map else [],
                        unit="unit"
                    )]
                    processed_kpis.add(sub)
        
        logger.info(f"ğŸ“¦ ë¶„ì„ ëŒ€ìƒ ë°ì´í„° êµ¬ì„± ì™„ë£Œ: {len(filtered_data)} KPIs")
        
        # 2. Choi Judging (ì•Œê³ ë¦¬ì¦˜ ìˆ˜í–‰)
        dummy_filter = FilteringResult(valid_time_slots={}, filter_ratio=0.0) # í•„í„°ë§ì€ ì´ë¯¸ ìˆ˜í–‰ë˜ì—ˆë‹¤ê³  ê°€ì •
        result = judgement_strategy.apply(filtered_data, dummy_filter, choi_config)
        
        # 3. Result Processing (ê²°ê³¼ ì²˜ë¦¬)
        kpi_judgements = result.get("kpi_judgement", {})
        
        logger.info(f"ğŸ§  ì•Œê³ ë¦¬ì¦˜ íŒì • ì™„ë£Œ. íŒì • í•­ëª© ìˆ˜: {len(kpi_judgements)}")
        
        for topic, res in kpi_judgements.items():
            if res.final_result != JudgementType.OK:
                # ì´ìƒ ì§•í›„ ë°œê²¬ (Anomaly Found)
                logger.warning(f"ğŸš¨ ì´ìƒ ì§•í›„ ê°ì§€: {topic} - {res.final_result.value}")
                anomalies.append({
                    "is_anomaly": True,
                    "severity": "P1" if res.final_result == JudgementType.NOK else "P2",
                    "title": f"KPI Anomaly: {topic}",
                    "description": f"Judgement: {res.final_result.value}. {res.summary_text}",
                    "related_kpis": [res.main_kpi_name] + [s['kpi_name'] for s in res.sub_results],
                    "root_cause": "Choi Algorithm Analysis",
                    "action_plan": "Check related KPIs"
                })

    except Exception as e:
        logger.error(f"âŒ Choi ì•Œê³ ë¦¬ì¦˜ ìˆ˜í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        anomalies.append({
             "is_anomaly": True,
             "severity": "P3",
             "title": "Algorithm Error",
             "description": f"Choi Algorithm Failed: {str(e)}",
             "related_kpis": [],
             "root_cause": "System Error",
             "action_plan": "Debug Logic"
        })
    
    log_msg = f"ğŸ” Choi Algorithm Analyzed. Found {len(anomalies)} anomalies."
    logger.info(log_msg)
    return {"anomalies": anomalies, "logs": [log_msg]}





