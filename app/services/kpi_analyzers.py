"""
KPI ë¶„ì„ ê·œì¹™ êµ¬í˜„ (5ì¥)

ì´ ëª¨ë“ˆì€ SOLID ì›ì¹™ì„ ì™„ë²½íˆ ì¤€ìˆ˜í•˜ì—¬ ê° KPI ë¶„ì„ ê·œì¹™ì„
ë…ë¦½ì ì¸ í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

SOLID ì›ì¹™ ì ìš©:
- Single Responsibility: ê° ë¶„ì„ê¸°ëŠ” í•˜ë‚˜ì˜ íŒì • ê·œì¹™ë§Œ ë‹´ë‹¹
- Open/Closed: ìƒˆë¡œìš´ íŒì • ê·œì¹™ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ìŒ
- Liskov Substitution: ëª¨ë“  ë¶„ì„ê¸°ëŠ” ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
- Interface Segregation: ê° ë¶„ì„ê¸°ëŠ” í•„ìš”í•œ ë©”ì„œë“œë§Œ êµ¬í˜„
- Dependency Inversion: ì¶”ìƒí™”ì— ì˜ì¡´, êµ¬ì²´ í´ë˜ìŠ¤ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ

PRD ì°¸ì¡°: ì„¹ì…˜ 2.3 (í†µê³„ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜)
"""

from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Protocol, Tuple
from dataclasses import dataclass
from enum import Enum
import logging
import numpy as np

from ..models.judgement import (
    PegSampleSeries,
    PegPeriodStats,
    PegCompareMetrics,
    PegCompareDecision,
    JudgementType,
    CompareDetail,
    KPIPositivity
)
from ..utils.logging_decorators import log_analyzer_execution
from ..exceptions import KPIAnalysisError, InsufficientDataError

logger = logging.getLogger(__name__)


# =============================================================================
# KPI ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤
# =============================================================================

@dataclass(frozen=True)
class KPIAnalysisResult:
    """
    KPI ë¶„ì„ ê²°ê³¼ (ë¶ˆë³€ ê°ì²´)
    
    ê° ë¶„ì„ê¸°ì˜ ê²°ê³¼ë¥¼ í‘œí˜„í•˜ëŠ” ë¶ˆë³€ ë°ì´í„° í´ë˜ìŠ¤
    """
    judgement_type: JudgementType
    compare_detail: CompareDetail
    reasoning: str
    confidence: float
    metrics: Dict[str, Any]
    thresholds_used: Dict[str, float]
    
    def __post_init__(self):
        """í›„ì²˜ë¦¬ ê²€ì¦"""
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError(f"Confidence must be between 0.0 and 1.0, got {self.confidence}")


class AnalysisRulePriority(Enum):
    """
    ë¶„ì„ ê·œì¹™ ìš°ì„ ìˆœìœ„ (5ì¥)
    
    ë†’ì€ ê°’ì´ ë†’ì€ ìš°ì„ ìˆœìœ„
    """
    CANT_JUDGE = 100
    HIGH_VARIATION = 90
    IMPROVE = 80
    DEGRADE = 80
    HIGH_DELTA = 70
    MEDIUM_DELTA = 60
    LOW_DELTA = 50
    SIMILAR = 40


# =============================================================================
# KPI ë¶„ì„ê¸° ì¸í„°í˜ì´ìŠ¤ (Protocol ì‚¬ìš©)
# =============================================================================

class KPIAnalyzer(Protocol):
    """
    KPI ë¶„ì„ê¸° í”„ë¡œí† ì½œ
    
    Protocolì„ ì‚¬ìš©í•˜ì—¬ ë• íƒ€ì´í•‘ ì§€ì› ë° ë” ìœ ì—°í•œ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
    """
    
    def analyze(self, 
                pre_stats: PegPeriodStats,
                post_stats: PegPeriodStats,
                compare_metrics: PegCompareMetrics,
                config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        KPI ë¶„ì„ ì‹¤í–‰
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            config: ë¶„ì„ ì„¤ì •
            
        Returns:
            Optional[KPIAnalysisResult]: ë¶„ì„ ê²°ê³¼ (í•´ë‹¹ ì—†ìœ¼ë©´ None)
        """
        ...
    
    def get_priority(self) -> int:
        """ë¶„ì„ ê·œì¹™ ìš°ì„ ìˆœìœ„ ë°˜í™˜"""
        ...
    
    def get_analyzer_info(self) -> Dict[str, Any]:
        """ë¶„ì„ê¸° ì •ë³´ ë°˜í™˜"""
        ...


# =============================================================================
# ì¶”ìƒ ê¸°ë³¸ ë¶„ì„ê¸° í´ë˜ìŠ¤
# =============================================================================

class BaseKPIAnalyzer(ABC):
    """
    KPI ë¶„ì„ê¸° ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤
    
    ê³µí†µ ê¸°ëŠ¥ê³¼ í…œí”Œë¦¿ ë©”ì„œë“œ íŒ¨í„´ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, analyzer_name: str, priority: AnalysisRulePriority, version: str = "1.0.0"):
        """
        ê¸°ë³¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            analyzer_name: ë¶„ì„ê¸° ì´ë¦„
            priority: ê·œì¹™ ìš°ì„ ìˆœìœ„
            version: ë²„ì „
        """
        self.analyzer_name = analyzer_name
        self.priority = priority
        self.version = version
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        self.logger.info(f"ğŸ› ï¸ KPI ë¶„ì„ê¸° '{analyzer_name}' v{version} ì´ˆê¸°í™” (ìš°ì„ ìˆœìœ„: {priority.value})")
    
    @log_analyzer_execution()
    def analyze(self, 
                pre_stats: PegPeriodStats,
                post_stats: PegPeriodStats,
                compare_metrics: PegCompareMetrics,
                config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        [Template Method] KPI ë¶„ì„ ì‹¤í–‰
        
        ë¶„ì„ í”„ë¡œì„¸ìŠ¤ì˜ ë¼ˆëŒ€ë¥¼ ì •ì˜í•©ë‹ˆë‹¤:
        1. ì„¤ì • ê²€ì¦
        2. ì…ë ¥ ë°ì´í„° ê²€ì¦
        3. ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
        4. ì‹¤ì œ ë¶„ì„ ë¡œì§ ì‹¤í–‰ (í•˜ìœ„ í´ë˜ìŠ¤)
        5. ê²°ê³¼ ê²€ì¦
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            config: ë¶„ì„ ì„¤ì •
            
        Returns:
            Optional[KPIAnalysisResult]: ë¶„ì„ ê²°ê³¼ (í•´ë‹¹ ì—†ìœ¼ë©´ None)
        """
        try:
            # 1. ì„¤ì • ê²€ì¦
            if not self._validate_config(config):
                raise ValueError(f"Invalid config for {self.analyzer_name}")
            
            # 2. ì…ë ¥ ë°ì´í„° ê²€ì¦
            if not self._validate_input_data(pre_stats, post_stats, compare_metrics):
                self.logger.debug(f"âš ï¸ {self.analyzer_name}: ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨, ë¶„ì„ ê±´ë„ˆëœ€")
                return None
            
            # 3. ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
            if not self._is_rule_applicable(pre_stats, post_stats, compare_metrics, config):
                # self.logger.debug(f"â„¹ï¸ {self.analyzer_name}: ê·œì¹™ ì ìš© ì¡°ê±´ ë¯¸ì¶©ì¡±, ê±´ë„ˆëœ€")
                return None
            
            # 4. ì‹¤ì œ ë¶„ì„ ë¡œì§ ì‹¤í–‰ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)
            self.logger.debug(f"ğŸš€ {self.analyzer_name} ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            analysis_result = self._execute_analysis(pre_stats, post_stats, compare_metrics, config)
            
            # 5. ê²°ê³¼ ê²€ì¦
            if analysis_result and not self._validate_result(analysis_result):
                raise RuntimeError(f"Invalid analysis result from {self.analyzer_name}")
            
            if analysis_result:
                self.logger.info(f"âœ… {self.analyzer_name} ë¶„ì„ ì™„ë£Œ: "
                               f"{analysis_result.judgement_type} ({analysis_result.compare_detail})")
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"âŒ {self.analyzer_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    @abstractmethod
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        [Abstract] ì‹¤ì œ ë¶„ì„ ë¡œì§ êµ¬í˜„
        
        í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬ì²´ì ì¸ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        pass
    
    @abstractmethod
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """
        [Abstract] ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
        
        í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì „ì œ ì¡°ê±´ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        pass
    
    def _validate_config(self, config: Dict[str, Any]) -> bool:
        """
        ê¸°ë³¸ ì„¤ì • ê²€ì¦
        
        Args:
            config: ê²€ì¦í•  ì„¤ì •
            
        Returns:
            bool: ìœ íš¨ì„± ì—¬ë¶€
        """
        try:
            if not isinstance(config, dict):
                self.logger.error("Config must be a dictionary")
                return False
            
            # í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì¶”ê°€ ê²€ì¦ ìˆ˜í–‰
            return self._validate_specific_config(config)
            
        except Exception as e:
            self.logger.error(f"Config validation error: {e}")
            return False
    
    @abstractmethod
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """í•˜ìœ„ í´ë˜ìŠ¤ë³„ íŠ¹í™” ì„¤ì • ê²€ì¦"""
        pass
    
    def _validate_input_data(self, 
                            pre_stats: PegPeriodStats,
                            post_stats: PegPeriodStats,
                            compare_metrics: PegCompareMetrics) -> bool:
        """
        ì…ë ¥ ë°ì´í„° ê²€ì¦
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            
        Returns:
            bool: ìœ íš¨ì„± ì—¬ë¶€
        """
        try:
            if not isinstance(pre_stats, PegPeriodStats):
                self.logger.error("pre_stats must be PegPeriodStats instance")
                return False
            
            if not isinstance(post_stats, PegPeriodStats):
                self.logger.error("post_stats must be PegPeriodStats instance")
                return False
            
            if not isinstance(compare_metrics, PegCompareMetrics):
                self.logger.error("compare_metrics must be PegCompareMetrics instance")
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"Input data validation error: {e}")
            return False
    
    def _validate_result(self, result: KPIAnalysisResult) -> bool:
        """
        ê²°ê³¼ ê²€ì¦
        
        Args:
            result: ê²€ì¦í•  ê²°ê³¼
            
        Returns:
            bool: ìœ íš¨ì„± ì—¬ë¶€
        """
        try:
            if not isinstance(result, KPIAnalysisResult):
                self.logger.error("Result must be KPIAnalysisResult instance")
                return False
            
            if not result.reasoning:
                self.logger.error("Reasoning cannot be empty")
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"Result validation error: {e}")
            return False
    
    def get_priority(self) -> int:
        """ë¶„ì„ ê·œì¹™ ìš°ì„ ìˆœìœ„ ë°˜í™˜"""
        return self.priority.value
    
    def get_analyzer_info(self) -> Dict[str, Any]:
        """
        ë¶„ì„ê¸° ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: ë¶„ì„ê¸° ë©”íƒ€ë°ì´í„°
        """
        return {
            "name": self.analyzer_name,
            "version": self.version,
            "priority": self.priority.value,
            "type": "kpi_analyzer",
            "description": f"KPI analyzer implementation: {self.analyzer_name}"
        }


# =============================================================================
# Can't Judge ë¶„ì„ê¸° (ìµœê³  ìš°ì„ ìˆœìœ„)
# =============================================================================

class CantJudgeAnalyzer(BaseKPIAnalyzer):
    """
    Can't Judge ë¶„ì„ê¸°
    
    pre ë˜ëŠ” post ë°ì´í„°ì— ND(No Data)ê°€ í¬í•¨ëœ ê²½ìš°ë¥¼ íƒì§€í•˜ì—¬ íŒì • ë¶ˆê°€ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    (NDëŠ” ë°ì´í„°ê°€ ì—†ëŠ” ìƒíƒœë¥¼ ì˜ë¯¸)
    
    Single Responsibility: Can't Judge ì¡°ê±´ ê²€ì‚¬ë§Œ ë‹´ë‹¹
    """
    
    def __init__(self):
        """Can't Judge ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("CantJudgeAnalyzer", AnalysisRulePriority.CANT_JUDGE)
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """
        [Rule] Can't Judge ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
        
        NDê°€ í¬í•¨ëœ ê²½ìš°ì—ë§Œ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
        (ND ë¹„ìœ¨ > 0)
        """
        return compare_metrics.has_nd or pre_stats.nd_ratio > 0 or post_stats.nd_ratio > 0
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        [Analysis] Can't Judge ë¶„ì„ ì‹¤í–‰
        
        ND íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ íŒì • ë¶ˆê°€ ì‚¬ìœ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            config: ë¶„ì„ ì„¤ì •
            
        Returns:
            Optional[KPIAnalysisResult]: Can't Judge ë¶„ì„ ê²°ê³¼
        """
        try:
            # ND ìƒì„¸ ë¶„ì„
            nd_analysis = self._analyze_nd_details(pre_stats, post_stats)
            
            reasoning = self._generate_cant_judge_reasoning(nd_analysis)
            
            self.logger.debug(f"ğŸ” ND ë¶„ì„ ê²°ê³¼: {nd_analysis['nd_pattern']} (Pre: {nd_analysis['pre_nd_ratio']:.1%}, Post: {nd_analysis['post_nd_ratio']:.1%})")
            
            return KPIAnalysisResult(
                judgement_type=JudgementType.CANT_JUDGE,
                compare_detail=CompareDetail.CANT_JUDGE,
                reasoning=reasoning,
                confidence=1.0,  # ND ì¡´ì¬ëŠ” í™•ì‹¤í•œ ì¡°ê±´ì´ë¯€ë¡œ ì‹ ë¢°ë„ 1.0
                metrics=nd_analysis,
                thresholds_used={}
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Can't Judge ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def _analyze_nd_details(self, pre_stats: PegPeriodStats, post_stats: PegPeriodStats) -> Dict[str, Any]:
        """
        [Helper] ND ìƒì„¸ ë¶„ì„
        
        Pre/Post ê¸°ê°„ë³„ ND ë¹„ìœ¨ê³¼ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Returns:
            Dict[str, Any]: ND ë¶„ì„ ì„¸ë¶€ ì •ë³´
        """
        return {
            "pre_nd_ratio": pre_stats.nd_ratio,
            "post_nd_ratio": post_stats.nd_ratio,
            "pre_sample_count": pre_stats.sample_count,
            "post_sample_count": post_stats.sample_count,
            "nd_pattern": self._determine_nd_pattern(pre_stats.nd_ratio, post_stats.nd_ratio)
        }
    
    def _determine_nd_pattern(self, pre_nd_ratio: float, post_nd_ratio: float) -> str:
        """[Helper] ND íŒ¨í„´ ê²°ì •"""
        if pre_nd_ratio > 0 and post_nd_ratio > 0:
            return "both_periods"
        elif pre_nd_ratio > 0:
            return "pre_only"
        elif post_nd_ratio > 0:
            return "post_only"
        else:
            return "none"
    
    def _generate_cant_judge_reasoning(self, nd_analysis: Dict[str, Any]) -> str:
        """[Helper] Can't Judge íŒì • ê·¼ê±° ìƒì„±"""
        pattern = nd_analysis["nd_pattern"]
        pre_ratio = nd_analysis["pre_nd_ratio"]
        post_ratio = nd_analysis["post_nd_ratio"]
        
        if pattern == "both_periods":
            return f"íŒì • ë¶ˆê°€: Pre({pre_ratio:.1%}) ë° Post({post_ratio:.1%}) ê¸°ê°„ ëª¨ë‘ ND í¬í•¨"
        elif pattern == "pre_only":
            return f"íŒì • ë¶ˆê°€: Pre ê¸°ê°„ì— ND í¬í•¨ ({pre_ratio:.1%})"
        elif pattern == "post_only":
            return f"íŒì • ë¶ˆê°€: Post ê¸°ê°„ì— ND í¬í•¨ ({post_ratio:.1%})"
        else:
            return "íŒì • ë¶ˆê°€: ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ"
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """[Validation] Can't Judge ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦ - ì¶”ê°€ ì„¤ì • ë¶ˆí•„ìš”"""
        return True


# =============================================================================
# High Variation ë¶„ì„ê¸°
# =============================================================================

# =============================================================================
# High Variation ë¶„ì„ê¸°
# =============================================================================

class HighVariationAnalyzer(BaseKPIAnalyzer):
    """
    High Variation ë¶„ì„ê¸°
    
    ë³€ë™ê³„ìˆ˜(CV)ê°€ ì„ê³„ê°’(Î²4)ì„ ì´ˆê³¼í•˜ëŠ”ì§€ ê²€ì‚¬í•˜ì—¬ ë°ì´í„° ë³€ë™ì„±ì´ í° ê²½ìš°ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    - CV(pre) > Î²4 ë˜ëŠ” CV(post) > Î²4
    - íŠ¹ìˆ˜ ì¼€ì´ìŠ¤: ND/Zero êµì°¨ ë°œìƒ ë“±ì˜ í†µê³„ì  ë¶ˆì•ˆì • ìƒíƒœ
    
    Single Responsibility: High Variation ì¡°ê±´ ê²€ì‚¬ë§Œ ë‹´ë‹¹
    """
    
    def __init__(self):
        """High Variation ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("HighVariationAnalyzer", AnalysisRulePriority.HIGH_VARIATION)
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """
        [Rule] High Variation ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
        
        CV ê³„ì‚°ì´ ê°€ëŠ¥í•œ ê²½ìš°(ND ì—†ìŒ)ì—ë§Œ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
        ë‹¨, íŠ¹ìˆ˜ ì¼€ì´ìŠ¤(ND/Zero êµì°¨)ë„ ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ND ì²´í¬ëŠ” ì™„í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ NDê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ê°€ì •í•˜ë˜, ë¡œì§ ë‚´ë¶€ì—ì„œ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬)
        """
        return (pre_stats.cv is not None or post_stats.cv is not None) and not compare_metrics.has_nd
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        [Analysis] High Variation ë¶„ì„ ì‹¤í–‰
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            config: ë¶„ì„ ì„¤ì •
            
        Returns:
            Optional[KPIAnalysisResult]: High Variation ë¶„ì„ ê²°ê³¼
        """
        try:
            beta_4 = config.get("beta_4", 10.0)
            
            # CV ë° íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ë¶„ì„
            cv_analysis = self._analyze_coefficient_of_variation(pre_stats, post_stats, beta_4)
            
            if cv_analysis["is_high_variation"]:
                reasoning = self._generate_high_variation_reasoning(cv_analysis, beta_4)
                
                self.logger.debug(f"ğŸ“‰ High Variation ê°ì§€: {reasoning}")
                
                return KPIAnalysisResult(
                    judgement_type=JudgementType.CANT_JUDGE,  # High Variationì€ íŒì • ë¶ˆê°€ë¡œ ì²˜ë¦¬
                    compare_detail=CompareDetail.HIGH_VARIATION,
                    reasoning=reasoning,
                    confidence=1.0,  # CV ê³„ì‚°ì€ í™•ì‹¤í•¨
                    metrics=cv_analysis,
                    thresholds_used={"beta_4": beta_4}
                )
            
            return None  # High Variationì´ ì•„ë‹˜
            
        except Exception as e:
            self.logger.error(f"âŒ High Variation ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def _analyze_coefficient_of_variation(self, 
                                        pre_stats: PegPeriodStats, 
                                        post_stats: PegPeriodStats, 
                                        beta_4: float) -> Dict[str, Any]:
        """
        [Helper] ë³€ë™ê³„ìˆ˜(CV) ë¶„ì„
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            beta_4: CV ì„ê³„ê°’
            
        Returns:
            Dict[str, Any]: CV ë¶„ì„ ê²°ê³¼
        """
        try:
            # Pre ê¸°ê°„ CV ë¶„ì„
            pre_cv = pre_stats.cv if pre_stats.cv is not None else 0.0
            pre_exceeds = pre_cv > beta_4
            
            # Post ê¸°ê°„ CV ë¶„ì„
            post_cv = post_stats.cv if post_stats.cv is not None else 0.0
            post_exceeds = post_cv > beta_4
            
            # High Variation íŒì •
            is_high_variation = pre_exceeds or post_exceeds
            
            # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬ (5.2 High Variation 2-6í•­)
            special_cases = self._check_special_variation_cases(pre_stats, post_stats)
            
            return {
                "pre_cv": pre_cv,
                "post_cv": post_cv,
                "beta_4_threshold": beta_4,
                "pre_exceeds_threshold": pre_exceeds,
                "post_exceeds_threshold": post_exceeds,
                "is_high_variation": is_high_variation or special_cases["has_special_case"],
                "special_cases": special_cases,
                "max_cv": max(pre_cv, post_cv),
                "cv_ratio": max(pre_cv, post_cv) / beta_4 if beta_4 > 0 else 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ CV ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"is_high_variation": False, "error": str(e)}
    
    def _check_special_variation_cases(self, pre_stats: PegPeriodStats, post_stats: PegPeriodStats) -> Dict[str, Any]:
        """
        [Helper] High Variation íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê²€ì‚¬ (5.2 í•­ëª© 2-6)
        
        NDì™€ ìœ íš¨ê°’ì´ êµì°¨í•˜ê±°ë‚˜, Zeroì™€ Non-Zeroê°€ êµì°¨í•˜ëŠ” ê²½ìš° ë“±
        í†µê³„ì ìœ¼ë¡œ ë¶ˆì•ˆì •í•œ ìƒíƒœë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.
        """
        special_cases = []
        
        # 2. Preê°€ NDê°€ ì•„ë‹ˆê³  Postê°€ NDì¸ ê²½ìš° Î´ = -100%
        if pre_stats.nd_ratio == 0 and post_stats.nd_ratio > 0:
            special_cases.append("pre_valid_post_nd")
        
        # 3. Preê°€ NDì´ê³  Postê°€ NDê°€ ì•„ë‹Œ ê²½ìš° Î´ = 100%
        if pre_stats.nd_ratio > 0 and post_stats.nd_ratio == 0:
            special_cases.append("pre_nd_post_valid")
        
        # 4-5. Zero ê´€ë ¨ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ (% í†µê³„ê°€ ì•„ë‹Œ ê²½ìš°)
        if pre_stats.zero_ratio == 0 and post_stats.zero_ratio > 0:
            special_cases.append("pre_nonzero_post_zero")
        
        if pre_stats.zero_ratio > 0 and post_stats.zero_ratio == 0:
            special_cases.append("pre_zero_post_nonzero")
        
        # 6. ì¼ë¶€ ìƒ˜í”Œì´ NDì¸ ê²½ìš°
        if 0 < pre_stats.nd_ratio < 1 or 0 < post_stats.nd_ratio < 1:
            special_cases.append("partial_nd_samples")
        
        return {
            "has_special_case": len(special_cases) > 0,
            "cases": special_cases,
            "case_count": len(special_cases)
        }
    
    def _generate_high_variation_reasoning(self, cv_analysis: Dict[str, Any], beta_4: float) -> str:
        """[Helper] High Variation íŒì • ê·¼ê±° ìƒì„±"""
        pre_cv = cv_analysis["pre_cv"]
        post_cv = cv_analysis["post_cv"]
        special_cases = cv_analysis["special_cases"]
        
        if special_cases["has_special_case"]:
            case_descriptions = {
                "pre_valid_post_nd": "Post ê¸°ê°„ì´ ND (Î´ = -100%)",
                "pre_nd_post_valid": "Pre ê¸°ê°„ì´ ND (Î´ = 100%)", 
                "pre_nonzero_post_zero": "Post ê¸°ê°„ì´ 0 (Î´ = -100%)",
                "pre_zero_post_nonzero": "Pre ê¸°ê°„ì´ 0 (Î´ = 100%)",
                "partial_nd_samples": "ì¼ë¶€ ìƒ˜í”Œì´ ND"
            }
            
            case_strs = [case_descriptions.get(case, case) for case in special_cases["cases"]]
            return f"High Variation: {', '.join(case_strs)}"
        
        if cv_analysis["pre_exceeds_threshold"] and cv_analysis["post_exceeds_threshold"]:
            return f"High Variation: Pre CV({pre_cv:.1f}) ë° Post CV({post_cv:.1f}) > Î²4({beta_4})"
        elif cv_analysis["pre_exceeds_threshold"]:
            return f"High Variation: Pre CV({pre_cv:.1f}) > Î²4({beta_4})"
        elif cv_analysis["post_exceeds_threshold"]:
            return f"High Variation: Post CV({post_cv:.1f}) > Î²4({beta_4})"
        else:
            return f"High Variation: íŠ¹ìˆ˜ ì¡°ê±´ ë§Œì¡±"
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """[Validation] High Variation ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦"""
        beta_4 = config.get("beta_4")
        if beta_4 is None:
            self.logger.error("beta_4 threshold is required for High Variation detection")
            return False
        
        if not isinstance(beta_4, (int, float)) or beta_4 <= 0:
            self.logger.error(f"beta_4 must be a positive number, got {beta_4}")
            return False
        
        return True


# =============================================================================
# Improve/Degrade ë¶„ì„ê¸°
# =============================================================================

# =============================================================================
# Improve/Degrade ë¶„ì„ê¸°
# =============================================================================

class ImproveAnalyzer(BaseKPIAnalyzer):
    """
    Improve ë¶„ì„ê¸°
    
    KPI ê·¹ì„±(Positivity)ì— ë”°ë¼ ì„±ëŠ¥ 'ê°œì„ (Improve)' ì—¬ë¶€ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    - Positive KPI (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ): max(pre) < min(post)
    - Negative KPI (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ): min(pre) > max(post)
    
    ë¶„í¬ê°€ ì™„ì „íˆ ë¶„ë¦¬ë˜ì–´ ê°œì„ ëœ ë°©í–¥ìœ¼ë¡œ ì´ë™í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """Improve ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("ImproveAnalyzer", AnalysisRulePriority.IMPROVE)
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """
        [Rule] Improve ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
        
        min/max í†µê³„ê°€ ì¡´ì¬í•˜ê³  NDê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
        """
        return (not compare_metrics.has_nd and 
                pre_stats.min is not None and pre_stats.max is not None and
                post_stats.min is not None and post_stats.max is not None)
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        [Analysis] Improve ë¶„ì„ ì‹¤í–‰
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            config: ë¶„ì„ ì„¤ì • (kpi_positivity í¬í•¨)
            
        Returns:
            Optional[KPIAnalysisResult]: Improve ë¶„ì„ ê²°ê³¼
        """
        try:
            # KPI ê·¹ì„± í™•ì¸ (ì„¤ì •ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨, í˜„ì¬ëŠ” ê¸°ë³¸ê°’ positive)
            kpi_positivity = config.get("kpi_positivity", "positive")
            
            # ë¶„í¬ êµì°¨ ë¶„ì„
            distribution_analysis = self._analyze_distribution_separation(
                pre_stats, post_stats, kpi_positivity
            )
            
            if distribution_analysis["is_improve"]:
                reasoning = self._generate_improve_reasoning(
                    distribution_analysis, kpi_positivity
                )
                
                self.logger.debug(f"ğŸ“ˆ Improve ê°ì§€: {reasoning}")
                
                return KPIAnalysisResult(
                    judgement_type=JudgementType.NOK,  # ImproveëŠ” ë³€í™”ê°€ í¬ë¯€ë¡œ NOKë¡œ ë¶„ë¥˜ (PLM ê²€ì¦ í•„ìš”)
                    compare_detail=CompareDetail.IMPROVE,
                    reasoning=reasoning,
                    confidence=0.9,  # ë¶„í¬ ë¶„ë¦¬ëŠ” ê°•ë ¥í•œ ì¦ê±°
                    metrics=distribution_analysis,
                    thresholds_used={}
                )
            
            return None  # Improveê°€ ì•„ë‹˜
            
        except Exception as e:
            self.logger.error(f"âŒ Improve ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def _analyze_distribution_separation(self, 
                                       pre_stats: PegPeriodStats, 
                                       post_stats: PegPeriodStats, 
                                       kpi_positivity: str) -> Dict[str, Any]:
        """
        [Helper] ë¶„í¬ ë¶„ë¦¬ ë¶„ì„
        
        Preì™€ Postì˜ ë¶„í¬(min~max ë²”ìœ„)ê°€ ì„œë¡œ ê²¹ì¹˜ì§€ ì•Šê³  ê°œì„ ëœ ë°©í–¥ìœ¼ë¡œ ë¶„ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        """
        try:
            pre_min, pre_max = pre_stats.min, pre_stats.max
            post_min, post_max = post_stats.min, post_stats.max
            
            if kpi_positivity == "positive":
                # Positive KPI: max(pre) < min(post) â†’ Improve (Postê°€ ì „ì²´ì ìœ¼ë¡œ ë” ë†’ìŒ)
                is_improve = pre_max < post_min
                comparison_type = "max_pre_vs_min_post"
                comparison_values = {"pre_max": pre_max, "post_min": post_min}
            else:
                # Negative KPI: min(pre) > max(post) â†’ Improve (Postê°€ ì „ì²´ì ìœ¼ë¡œ ë” ë‚®ìŒ)
                is_improve = pre_min > post_max
                comparison_type = "min_pre_vs_max_post"
                comparison_values = {"pre_min": pre_min, "post_max": post_max}
            
            # ë¶„í¬ ê²¹ì¹¨ ì •ë„ ê³„ì‚° (ì°¸ê³ ìš©)
            overlap_analysis = self._calculate_distribution_overlap(pre_stats, post_stats)
            
            return {
                "is_improve": is_improve,
                "kpi_positivity": kpi_positivity,
                "comparison_type": comparison_type,
                "comparison_values": comparison_values,
                "distribution_overlap": overlap_analysis,
                "separation_clear": not overlap_analysis["has_overlap"]
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë¶„í¬ ë¶„ë¦¬ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"is_improve": False, "error": str(e)}
    
    def _calculate_distribution_overlap(self, pre_stats: PegPeriodStats, post_stats: PegPeriodStats) -> Dict[str, Any]:
        """
        [Helper] ë¶„í¬ ê²¹ì¹¨ ê³„ì‚°
        
        Pre/Post ë²”ìœ„ê°€ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ì§€ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        try:
            # ë¶„í¬ ë²”ìœ„ ê³„ì‚°
            pre_range = [pre_stats.min, pre_stats.max]
            post_range = [post_stats.min, post_stats.max]
            
            # ê²¹ì¹¨ êµ¬ê°„ ê³„ì‚°
            overlap_start = max(pre_range[0], post_range[0])
            overlap_end = min(pre_range[1], post_range[1])
            
            has_overlap = overlap_start <= overlap_end
            overlap_size = max(0, overlap_end - overlap_start) if has_overlap else 0
            
            # ì „ì²´ ë²”ìœ„ ëŒ€ë¹„ ê²¹ì¹¨ ë¹„ìœ¨
            total_range = max(pre_range[1], post_range[1]) - min(pre_range[0], post_range[0])
            overlap_ratio = overlap_size / total_range if total_range > 0 else 0
            
            return {
                "has_overlap": has_overlap,
                "overlap_size": overlap_size,
                "overlap_ratio": overlap_ratio,
                "pre_range": pre_range,
                "post_range": post_range,
                "separation_distance": overlap_start - overlap_end if not has_overlap else 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë¶„í¬ ê²¹ì¹¨ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {"has_overlap": True, "error": str(e)}
    
    def _generate_improve_reasoning(self, distribution_analysis: Dict[str, Any], kpi_positivity: str) -> str:
        """[Helper] Improve íŒì • ê·¼ê±° ìƒì„±"""
        comparison_values = distribution_analysis["comparison_values"]
        overlap_info = distribution_analysis["distribution_overlap"]
        
        if kpi_positivity == "positive":
            pre_max = comparison_values["pre_max"]
            post_min = comparison_values["post_min"]
            return (f"ì„±ëŠ¥ ê°œì„ : Positive KPIì—ì„œ Pre ìµœëŒ“ê°’({pre_max:.1f}) < Post ìµœì†Ÿê°’({post_min:.1f}), "
                   f"ë¶„í¬ ë¶„ë¦¬ë¨ (ê²¹ì¹¨ ë¹„ìœ¨: {overlap_info['overlap_ratio']:.1%})")
        else:
            pre_min = comparison_values["pre_min"]
            post_max = comparison_values["post_max"]
            return (f"ì„±ëŠ¥ ê°œì„ : Negative KPIì—ì„œ Pre ìµœì†Ÿê°’({pre_min:.1f}) > Post ìµœëŒ“ê°’({post_max:.1f}), "
                   f"ë¶„í¬ ë¶„ë¦¬ë¨ (ê²¹ì¹¨ ë¹„ìœ¨: {overlap_info['overlap_ratio']:.1%})")
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """[Validation] Improve ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦"""
        kpi_positivity = config.get("kpi_positivity")
        if kpi_positivity and kpi_positivity not in ["positive", "negative"]:
            self.logger.error(f"Invalid kpi_positivity: {kpi_positivity}")
            return False
        return True


class DegradeAnalyzer(BaseKPIAnalyzer):
    """
    Degrade ë¶„ì„ê¸°
    
    KPI ê·¹ì„±ì— ë”°ë¼ ì„±ëŠ¥ 'ì €í•˜(Degrade)' ì—¬ë¶€ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    - Positive KPI (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ): min(pre) > max(post)
    - Negative KPI (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ): max(pre) < min(post)
    
    ë¶„í¬ê°€ ì™„ì „íˆ ë¶„ë¦¬ë˜ì–´ ì €í•˜ëœ ë°©í–¥ìœ¼ë¡œ ì´ë™í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """Degrade ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("DegradeAnalyzer", AnalysisRulePriority.DEGRADE)
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """
        [Rule] Degrade ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
        
        min/max í†µê³„ê°€ ì¡´ì¬í•˜ê³  NDê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
        """
        return (not compare_metrics.has_nd and 
                pre_stats.min is not None and pre_stats.max is not None and
                post_stats.min is not None and post_stats.max is not None)
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        [Analysis] Degrade ë¶„ì„ ì‹¤í–‰
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            config: ë¶„ì„ ì„¤ì •
            
        Returns:
            Optional[KPIAnalysisResult]: Degrade ë¶„ì„ ê²°ê³¼
        """
        try:
            # KPI ê·¹ì„± í™•ì¸
            kpi_positivity = config.get("kpi_positivity", "positive")
            
            # ë¶„í¬ êµì°¨ ë¶„ì„ (Improveì™€ ë°˜ëŒ€ ì¡°ê±´)
            distribution_analysis = self._analyze_distribution_separation(
                pre_stats, post_stats, kpi_positivity
            )
            
            if distribution_analysis["is_degrade"]:
                reasoning = self._generate_degrade_reasoning(
                    distribution_analysis, kpi_positivity
                )
                
                self.logger.debug(f"ğŸ“‰ Degrade ê°ì§€: {reasoning}")
                
                return KPIAnalysisResult(
                    judgement_type=JudgementType.NOK,  # DegradeëŠ” NOKë¡œ ë¶„ë¥˜
                    compare_detail=CompareDetail.DEGRADE,
                    reasoning=reasoning,
                    confidence=0.9,  # ë¶„í¬ ê¸°ë°˜ ë¶„ì„ì˜ ë†’ì€ ì‹ ë¢°ë„
                    metrics=distribution_analysis,
                    thresholds_used={}
                )
            
            return None  # Degradeê°€ ì•„ë‹˜
            
        except Exception as e:
            self.logger.error(f"âŒ Degrade ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def _analyze_distribution_separation(self, 
                                       pre_stats: PegPeriodStats, 
                                       post_stats: PegPeriodStats, 
                                       kpi_positivity: str) -> Dict[str, Any]:
        """
        [Helper] ë¶„í¬ ë¶„ë¦¬ ë¶„ì„ (Degrade ê´€ì )
        """
        try:
            pre_min, pre_max = pre_stats.min, pre_stats.max
            post_min, post_max = post_stats.min, post_stats.max
            
            if kpi_positivity == "positive":
                # Positive KPI: min(pre) > max(post) â†’ Degrade (Postê°€ ì „ì²´ì ìœ¼ë¡œ ë” ë‚®ìŒ)
                is_degrade = pre_min > post_max
                comparison_type = "min_pre_vs_max_post"
                comparison_values = {"pre_min": pre_min, "post_max": post_max}
            else:
                # Negative KPI: max(pre) < min(post) â†’ Degrade (Postê°€ ì „ì²´ì ìœ¼ë¡œ ë” ë†’ìŒ)
                is_degrade = pre_max < post_min
                comparison_type = "max_pre_vs_min_post"
                comparison_values = {"pre_max": pre_max, "post_min": post_min}
            
            # ë¶„í¬ ê²¹ì¹¨ ì •ë„ ê³„ì‚° (ImproveAnalyzer ë¡œì§ ì¬ì‚¬ìš©)
            improve_analyzer = ImproveAnalyzer()
            overlap_analysis = improve_analyzer._calculate_distribution_overlap(pre_stats, post_stats)
            
            return {
                "is_degrade": is_degrade,
                "kpi_positivity": kpi_positivity,
                "comparison_type": comparison_type,
                "comparison_values": comparison_values,
                "distribution_overlap": overlap_analysis,
                "separation_clear": not overlap_analysis["has_overlap"]
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë¶„í¬ ë¶„ë¦¬ ë¶„ì„ ì˜¤ë¥˜ (Degrade): {e}")
            return {"is_degrade": False, "error": str(e)}
    
    def _generate_degrade_reasoning(self, distribution_analysis: Dict[str, Any], kpi_positivity: str) -> str:
        """[Helper] Degrade íŒì • ê·¼ê±° ìƒì„±"""
        comparison_values = distribution_analysis["comparison_values"]
        overlap_info = distribution_analysis["distribution_overlap"]
        
        if kpi_positivity == "positive":
            pre_min = comparison_values["pre_min"]
            post_max = comparison_values["post_max"]
            return (f"ì„±ëŠ¥ ì €í•˜: Positive KPIì—ì„œ Pre ìµœì†Ÿê°’({pre_min:.1f}) > Post ìµœëŒ“ê°’({post_max:.1f}), "
                   f"ë¶„í¬ ë¶„ë¦¬ë¨ (ê²¹ì¹¨ ë¹„ìœ¨: {overlap_info['overlap_ratio']:.1%})")
        else:
            pre_max = comparison_values["pre_max"]
            post_min = comparison_values["post_min"]
            return (f"ì„±ëŠ¥ ì €í•˜: Negative KPIì—ì„œ Pre ìµœëŒ“ê°’({pre_max:.1f}) < Post ìµœì†Ÿê°’({post_min:.1f}), "
                   f"ë¶„í¬ ë¶„ë¦¬ë¨ (ê²¹ì¹¨ ë¹„ìœ¨: {overlap_info['overlap_ratio']:.1%})")
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """[Validation] Degrade ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦"""
        kpi_positivity = config.get("kpi_positivity")
        if kpi_positivity and kpi_positivity not in ["positive", "negative"]:
            self.logger.error(f"Invalid kpi_positivity: {kpi_positivity}")
            return False
        return True


# =============================================================================
# Similar ë¶„ì„ê¸° (ë³µì¡í•œ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬)
# =============================================================================

class SimilarAnalyzer(BaseKPIAnalyzer):
    """
    Similar ë¶„ì„ê¸°
    
    ë³µì¡í•œ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ë¥¼ ê°€ì§„ ë¶„ì„ê¸°ì…ë‹ˆë‹¤.
    1. íŠ¸ë˜í”½ ë³¼ë¥¨ ë¶„ë¥˜ (Î²0 ê¸°ì¤€)
    2. ë³¼ë¥¨ì— ë”°ë¥¸ ì„ê³„ê°’ ì„ íƒ (Î²1 ë˜ëŠ” Î²2)
    3. ìƒëŒ€ì  ë¸íƒ€ ê²€ì‚¬ (ì„ íƒëœ ì„ê³„ê°’)
    4. ì ˆëŒ€ì  ë¸íƒ€ ê²€ì‚¬ (Î²5)
    
    Single Responsibility: Similar ì¡°ê±´ ê²€ì‚¬ë§Œ ë‹´ë‹¹
    """
    
    def __init__(self):
        """Similar ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("SimilarAnalyzer", AnalysisRulePriority.SIMILAR)
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """
        Similar ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸
        
        í‰ê· ê°’ì´ ìˆê³  NDê°€ ì—†ìœ¼ë©°, Improve/Degradeê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì ìš©
        """
        return (not compare_metrics.has_nd and 
                pre_stats.mean is not None and post_stats.mean is not None and
                compare_metrics.delta_pct is not None)
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """
        Similar ë¶„ì„ ì‹¤í–‰
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            compare_metrics: ë¹„êµ ì§€í‘œ
            config: ë¶„ì„ ì„¤ì •
            
        Returns:
            Optional[KPIAnalysisResult]: Similar ë¶„ì„ ê²°ê³¼
        """
        try:
            # Î² ì„ê³„ê°’ë“¤ ì¶”ì¶œ
            beta_0 = config.get("beta_0", 1000.0)  # íŠ¸ë˜í”½ ë³¼ë¥¨ ì„ê³„ê°’
            beta_1 = config.get("beta_1", 5.0)     # ê³ íŠ¸ë˜í”½ ì„ê³„ê°’
            beta_2 = config.get("beta_2", 10.0)    # ì €íŠ¸ë˜í”½ ì„ê³„ê°’
            beta_5 = config.get("beta_5", 3.0)     # ì ˆëŒ€ê°’ ì„ê³„ê°’
            
            # 1ë‹¨ê³„: íŠ¸ë˜í”½ ë³¼ë¥¨ ë¶„ë¥˜
            volume_analysis = self._classify_traffic_volume(pre_stats, post_stats, beta_0)
            
            # 2ë‹¨ê³„: ë¸íƒ€ ê³„ì‚°
            delta_analysis = self._calculate_delta_percentage(pre_stats, post_stats)
            
            # 3ë‹¨ê³„: Similar íŒì • ë¡œì§ ì ìš©
            similar_analysis = self._apply_similar_logic(
                volume_analysis, delta_analysis, beta_1, beta_2, beta_5
            )
            
            if similar_analysis["is_similar"]:
                reasoning = self._generate_similar_reasoning(
                    similar_analysis, volume_analysis, delta_analysis
                )
                
                return KPIAnalysisResult(
                    judgement_type=JudgementType.OK,  # SimilarëŠ” OKë¡œ ë¶„ë¥˜
                    compare_detail=CompareDetail.SIMILAR,
                    reasoning=reasoning,
                    confidence=0.95,  # ìˆ˜í•™ì  ê³„ì‚°ì˜ ë†’ì€ ì‹ ë¢°ë„
                    metrics={**volume_analysis, **delta_analysis, **similar_analysis},
                    thresholds_used={
                        "beta_0": beta_0, "beta_1": beta_1, "beta_2": beta_2, "beta_5": beta_5
                    }
                )
            
            return None  # Similarê°€ ì•„ë‹˜
            
        except Exception as e:
            self.logger.error(f"Similar analysis error: {e}")
            raise
    
    def _classify_traffic_volume(self, 
                               pre_stats: PegPeriodStats, 
                               post_stats: PegPeriodStats, 
                               beta_0: float) -> Dict[str, Any]:
        """
        íŠ¸ë˜í”½ ë³¼ë¥¨ ë¶„ë¥˜ (Î²0 ê¸°ì¤€)
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            beta_0: íŠ¸ë˜í”½ ë³¼ë¥¨ ì„ê³„ê°’
            
        Returns:
            Dict[str, Any]: ë³¼ë¥¨ ë¶„ë¥˜ ê²°ê³¼
        """
        try:
            pre_mean = pre_stats.mean or 0.0
            post_mean = post_stats.mean or 0.0
            
            # 5.2 Similar ì¡°ê±´: pre < Î²0 OR post < Î²0 â†’ ì €íŠ¸ë˜í”½ (Î²2 ì ìš©)
            is_low_traffic = pre_mean < beta_0 or post_mean < beta_0
            
            # ê³ íŠ¸ë˜í”½: pre â‰¥ Î²0 AND post â‰¥ Î²0 â†’ ê³ íŠ¸ë˜í”½ (Î²1 ì ìš©)
            is_high_traffic = pre_mean >= beta_0 and post_mean >= beta_0
            
            # ì„ íƒëœ ì„ê³„ê°’ ê²°ì •
            if is_low_traffic:
                selected_threshold = 10.0  # Î²2 (ì €íŠ¸ë˜í”½ìš©)
                traffic_classification = "low"
            else:
                selected_threshold = 5.0   # Î²1 (ê³ íŠ¸ë˜í”½ìš©)
                traffic_classification = "high"
            
            return {
                "pre_mean": pre_mean,
                "post_mean": post_mean,
                "beta_0_threshold": beta_0,
                "is_low_traffic": is_low_traffic,
                "is_high_traffic": is_high_traffic,
                "traffic_classification": traffic_classification,
                "selected_threshold": selected_threshold,
                "threshold_type": "beta_2" if is_low_traffic else "beta_1"
            }
            
        except Exception as e:
            self.logger.error(f"Traffic volume classification error: {e}")
            return {"traffic_classification": "unknown", "selected_threshold": 10.0}
    
    def _calculate_delta_percentage(self, pre_stats: PegPeriodStats, post_stats: PegPeriodStats) -> Dict[str, Any]:
        """
        ë¸íƒ€ ë°±ë¶„ìœ¨ ê³„ì‚°
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            
        Returns:
            Dict[str, Any]: ë¸íƒ€ ê³„ì‚° ê²°ê³¼
        """
        try:
            pre_mean = pre_stats.mean or 0.0
            post_mean = post_stats.mean or 0.0
            
            # Î´ = (post-pre)/pre * 100 ê³„ì‚°
            if pre_mean == 0:
                if post_mean == 0:
                    delta_pct = 0.0
                    calculation_note = "both_zero"
                else:
                    delta_pct = 100.0 if post_mean > 0 else -100.0
                    calculation_note = "pre_zero_special_case"
            else:
                delta_pct = ((post_mean - pre_mean) / pre_mean) * 100
                calculation_note = "normal_calculation"
            
            # ì ˆëŒ“ê°’ ê³„ì‚°
            abs_delta = abs(delta_pct)
            
            return {
                "pre_mean": pre_mean,
                "post_mean": post_mean,
                "delta_percentage": delta_pct,
                "abs_delta": abs_delta,
                "calculation_note": calculation_note
            }
            
        except Exception as e:
            self.logger.error(f"Delta calculation error: {e}")
            return {"delta_percentage": 0.0, "abs_delta": 0.0, "calculation_note": "error"}
    
    def _apply_similar_logic(self, 
                           volume_analysis: Dict[str, Any], 
                           delta_analysis: Dict[str, Any], 
                           beta_1: float, 
                           beta_2: float, 
                           beta_5: float) -> Dict[str, Any]:
        """
        Similar íŒì • ë¡œì§ ì ìš©
        
        ë³µì¡í•œ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬:
        1. íŠ¸ë˜í”½ ë³¼ë¥¨ì— ë”°ë¥¸ ì„ê³„ê°’ ì„ íƒ
        2. ìƒëŒ€ì  ë¸íƒ€ ê²€ì‚¬ (Î²1 ë˜ëŠ” Î²2)
        3. ì ˆëŒ€ì  ë¸íƒ€ ê²€ì‚¬ (Î²5)
        4. ë‘ ì¡°ê±´ ëª¨ë‘ ë§Œì¡±í•´ì•¼ Similar
        
        Args:
            volume_analysis: ë³¼ë¥¨ ë¶„ë¥˜ ê²°ê³¼
            delta_analysis: ë¸íƒ€ ê³„ì‚° ê²°ê³¼
            beta_1: ê³ íŠ¸ë˜í”½ ì„ê³„ê°’
            beta_2: ì €íŠ¸ë˜í”½ ì„ê³„ê°’
            beta_5: ì ˆëŒ€ê°’ ì„ê³„ê°’
            
        Returns:
            Dict[str, Any]: Similar íŒì • ê²°ê³¼
        """
        try:
            abs_delta = delta_analysis["abs_delta"]
            selected_threshold = volume_analysis["selected_threshold"]
            
            # ì¡°ê±´ 1: ìƒëŒ€ì  ë¸íƒ€ ê²€ì‚¬ (ì„ íƒëœ ì„ê³„ê°’ ê¸°ì¤€)
            relative_check_passed = abs_delta <= selected_threshold
            
            # ì¡°ê±´ 2: ì ˆëŒ€ì  ë¸íƒ€ ê²€ì‚¬ (Î²5 ê¸°ì¤€)
            absolute_check_passed = abs_delta < beta_5
            
            # Similar íŒì •: ë‘ ì¡°ê±´ ëª¨ë‘ ë§Œì¡±í•´ì•¼ í•¨
            is_similar = relative_check_passed and absolute_check_passed
            
            return {
                "is_similar": is_similar,
                "relative_check_passed": relative_check_passed,
                "absolute_check_passed": absolute_check_passed,
                "selected_threshold": selected_threshold,
                "beta_5_threshold": beta_5,
                "abs_delta": abs_delta,
                "relative_margin": selected_threshold - abs_delta,
                "absolute_margin": beta_5 - abs_delta
            }
            
        except Exception as e:
            self.logger.error(f"Similar logic application error: {e}")
            return {"is_similar": False, "error": str(e)}
    
    def _generate_similar_reasoning(self, 
                                  similar_analysis: Dict[str, Any], 
                                  volume_analysis: Dict[str, Any], 
                                  delta_analysis: Dict[str, Any]) -> str:
        """Similar íŒì • ê·¼ê±° ìƒì„±"""
        traffic_type = volume_analysis["traffic_classification"]
        threshold_type = volume_analysis["threshold_type"]
        selected_threshold = similar_analysis["selected_threshold"]
        abs_delta = similar_analysis["abs_delta"]
        beta_5 = similar_analysis["beta_5_threshold"]
        
        return (f"ìœ ì‚¬ ìˆ˜ì¤€: {traffic_type.upper()} íŠ¸ë˜í”½ ({threshold_type}={selected_threshold}) ê¸°ì¤€ "
               f"|Î´|={abs_delta:.1f} â‰¤ {selected_threshold} AND |Î´| < {beta_5}, "
               f"ë‘ ì¡°ê±´ ëª¨ë‘ ë§Œì¡±")
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """Similar ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦"""
        required_betas = ["beta_0", "beta_1", "beta_2", "beta_5"]
        for beta in required_betas:
            value = config.get(beta)
            if value is None:
                self.logger.error(f"Required threshold {beta} is missing")
                return False
            
            if not isinstance(value, (int, float)) or value < 0:
                self.logger.error(f"{beta} must be a non-negative number, got {value}")
                return False
        
        # Î²1 < Î²2 ê´€ê³„ ê²€ì¦
        beta_1 = config.get("beta_1", 0)
        beta_2 = config.get("beta_2", 0)
        if beta_1 > beta_2:
            self.logger.warning(f"beta_1 ({beta_1}) > beta_2 ({beta_2}), unusual configuration")
        
        return True


# =============================================================================
# Delta ê³„ì¸µ ë¶„ì„ê¸°ë“¤ (Low/Medium/High Delta)
# =============================================================================

class LowDeltaAnalyzer(BaseKPIAnalyzer):
    """
    Low Delta ë¶„ì„ê¸°
    
    Î²2 < Î´ â‰¤ 2*Î²2 (ì €íŠ¸ë˜í”½) ë˜ëŠ” Î²1 < Î´ â‰¤ 2*Î²1 (ê³ íŠ¸ë˜í”½) ì¡°ê±´ ê²€ì‚¬
    
    Single Responsibility: Low Delta ì¡°ê±´ ê²€ì‚¬ë§Œ ë‹´ë‹¹
    """
    
    def __init__(self):
        """Low Delta ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("LowDeltaAnalyzer", AnalysisRulePriority.LOW_DELTA)
        
        # Similar ë¶„ì„ê¸° ë¡œì§ ì¬ì‚¬ìš© (DRY ì›ì¹™)
        self.similar_analyzer = SimilarAnalyzer()
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """Low Delta ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        return (not compare_metrics.has_nd and 
                pre_stats.mean is not None and post_stats.mean is not None and
                compare_metrics.delta_pct is not None)
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """Low Delta ë¶„ì„ ì‹¤í–‰"""
        try:
            # Î² ì„ê³„ê°’ë“¤ ì¶”ì¶œ
            beta_0 = config.get("beta_0", 1000.0)
            beta_1 = config.get("beta_1", 5.0)
            beta_2 = config.get("beta_2", 10.0)
            
            # Similar ë¶„ì„ê¸°ì˜ ë¡œì§ ì¬ì‚¬ìš©
            volume_analysis = self.similar_analyzer._classify_traffic_volume(pre_stats, post_stats, beta_0)
            delta_analysis = self.similar_analyzer._calculate_delta_percentage(pre_stats, post_stats)
            
            # Low Delta ì¡°ê±´ ê²€ì‚¬
            delta_classification = self._classify_delta_level(
                volume_analysis, delta_analysis, beta_1, beta_2
            )
            
            if delta_classification["is_low_delta"]:
                reasoning = self._generate_low_delta_reasoning(
                    delta_classification, volume_analysis, delta_analysis
                )
                
                return KPIAnalysisResult(
                    judgement_type=JudgementType.NOK,  # Low DeltaëŠ” NOK
                    compare_detail=CompareDetail.LOW_DELTA,
                    reasoning=reasoning,
                    confidence=0.95,
                    metrics={**volume_analysis, **delta_analysis, **delta_classification},
                    thresholds_used={"beta_0": beta_0, "beta_1": beta_1, "beta_2": beta_2}
                )
            
            return None
            
        except Exception as e:
            self.logger.error(f"Low Delta analysis error: {e}")
            raise
    
    def _classify_delta_level(self, 
                            volume_analysis: Dict[str, Any], 
                            delta_analysis: Dict[str, Any], 
                            beta_1: float, 
                            beta_2: float) -> Dict[str, Any]:
        """ë¸íƒ€ ìˆ˜ì¤€ ë¶„ë¥˜"""
        try:
            abs_delta = delta_analysis["abs_delta"]
            is_low_traffic = volume_analysis["is_low_traffic"]
            
            if is_low_traffic:
                # ì €íŠ¸ë˜í”½: Î²2 < Î´ â‰¤ 2*Î²2
                lower_bound = beta_2
                upper_bound = 2 * beta_2
                threshold_type = "beta_2"
            else:
                # ê³ íŠ¸ë˜í”½: Î²1 < Î´ â‰¤ 2*Î²1
                lower_bound = beta_1
                upper_bound = 2 * beta_1
                threshold_type = "beta_1"
            
            is_low_delta = lower_bound < abs_delta <= upper_bound
            
            return {
                "is_low_delta": is_low_delta,
                "lower_bound": lower_bound,
                "upper_bound": upper_bound,
                "threshold_type": threshold_type,
                "abs_delta": abs_delta,
                "within_range": is_low_delta
            }
            
        except Exception as e:
            self.logger.error(f"Delta level classification error: {e}")
            return {"is_low_delta": False, "error": str(e)}
    
    def _generate_low_delta_reasoning(self, 
                                    delta_classification: Dict[str, Any], 
                                    volume_analysis: Dict[str, Any], 
                                    delta_analysis: Dict[str, Any]) -> str:
        """Low Delta íŒì • ê·¼ê±° ìƒì„±"""
        traffic_type = volume_analysis["traffic_classification"]
        threshold_type = delta_classification["threshold_type"]
        lower_bound = delta_classification["lower_bound"]
        upper_bound = delta_classification["upper_bound"]
        abs_delta = delta_classification["abs_delta"]
        
        return (f"ë‚®ì€ ë³€í™”ëŸ‰: {traffic_type.upper()} íŠ¸ë˜í”½ ({threshold_type}) ê¸°ì¤€ "
               f"{lower_bound} < |Î´|={abs_delta:.1f} â‰¤ {upper_bound}")
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """Low Delta ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦"""
        required_betas = ["beta_0", "beta_1", "beta_2"]
        for beta in required_betas:
            if config.get(beta) is None:
                self.logger.error(f"Required threshold {beta} is missing")
                return False
        return True


class MediumDeltaAnalyzer(BaseKPIAnalyzer):
    """
    Medium Delta ë¶„ì„ê¸°
    
    2*Î²2 < Î´ â‰¤ Î²3 (ì €íŠ¸ë˜í”½) ë˜ëŠ” 2*Î²1 < Î´ â‰¤ Î²3 (ê³ íŠ¸ë˜í”½) ì¡°ê±´ ê²€ì‚¬
    
    Single Responsibility: Medium Delta ì¡°ê±´ ê²€ì‚¬ë§Œ ë‹´ë‹¹
    """
    
    def __init__(self):
        """Medium Delta ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("MediumDeltaAnalyzer", AnalysisRulePriority.MEDIUM_DELTA)
        
        # ê¸°ì¡´ ë¶„ì„ê¸° ë¡œì§ ì¬ì‚¬ìš©
        self.similar_analyzer = SimilarAnalyzer()
        self.low_delta_analyzer = LowDeltaAnalyzer()
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """Medium Delta ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        return (not compare_metrics.has_nd and 
                pre_stats.mean is not None and post_stats.mean is not None and
                compare_metrics.delta_pct is not None)
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """Medium Delta ë¶„ì„ ì‹¤í–‰"""
        try:
            # Î² ì„ê³„ê°’ë“¤ ì¶”ì¶œ
            beta_0 = config.get("beta_0", 1000.0)
            beta_1 = config.get("beta_1", 5.0)
            beta_2 = config.get("beta_2", 10.0)
            beta_3 = config.get("beta_3", 500.0)
            
            # ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©
            volume_analysis = self.similar_analyzer._classify_traffic_volume(pre_stats, post_stats, beta_0)
            delta_analysis = self.similar_analyzer._calculate_delta_percentage(pre_stats, post_stats)
            
            # Medium Delta ì¡°ê±´ ê²€ì‚¬
            delta_classification = self._classify_medium_delta_level(
                volume_analysis, delta_analysis, beta_1, beta_2, beta_3
            )
            
            if delta_classification["is_medium_delta"]:
                reasoning = self._generate_medium_delta_reasoning(
                    delta_classification, volume_analysis, delta_analysis
                )
                
                return KPIAnalysisResult(
                    judgement_type=JudgementType.NOK,  # Medium DeltaëŠ” NOK
                    compare_detail=CompareDetail.MEDIUM_DELTA,
                    reasoning=reasoning,
                    confidence=0.95,
                    metrics={**volume_analysis, **delta_analysis, **delta_classification},
                    thresholds_used={"beta_0": beta_0, "beta_1": beta_1, "beta_2": beta_2, "beta_3": beta_3}
                )
            
            return None
            
        except Exception as e:
            self.logger.error(f"Medium Delta analysis error: {e}")
            raise
    
    def _classify_medium_delta_level(self, 
                                   volume_analysis: Dict[str, Any], 
                                   delta_analysis: Dict[str, Any], 
                                   beta_1: float, 
                                   beta_2: float, 
                                   beta_3: float) -> Dict[str, Any]:
        """Medium Delta ìˆ˜ì¤€ ë¶„ë¥˜"""
        try:
            abs_delta = delta_analysis["abs_delta"]
            is_low_traffic = volume_analysis["is_low_traffic"]
            
            if is_low_traffic:
                # ì €íŠ¸ë˜í”½: 2*Î²2 < Î´ â‰¤ Î²3
                lower_bound = 2 * beta_2
                upper_bound = beta_3
                threshold_type = "2*beta_2"
            else:
                # ê³ íŠ¸ë˜í”½: 2*Î²1 < Î´ â‰¤ Î²3
                lower_bound = 2 * beta_1
                upper_bound = beta_3
                threshold_type = "2*beta_1"
            
            is_medium_delta = lower_bound < abs_delta <= upper_bound
            
            return {
                "is_medium_delta": is_medium_delta,
                "lower_bound": lower_bound,
                "upper_bound": upper_bound,
                "threshold_type": threshold_type,
                "abs_delta": abs_delta,
                "within_range": is_medium_delta
            }
            
        except Exception as e:
            self.logger.error(f"Medium delta classification error: {e}")
            return {"is_medium_delta": False, "error": str(e)}
    
    def _generate_medium_delta_reasoning(self, 
                                       delta_classification: Dict[str, Any], 
                                       volume_analysis: Dict[str, Any], 
                                       delta_analysis: Dict[str, Any]) -> str:
        """Medium Delta íŒì • ê·¼ê±° ìƒì„±"""
        traffic_type = volume_analysis["traffic_classification"]
        threshold_type = delta_classification["threshold_type"]
        lower_bound = delta_classification["lower_bound"]
        upper_bound = delta_classification["upper_bound"]
        abs_delta = delta_classification["abs_delta"]
        
        return (f"ì¤‘ê°„ ë³€í™”ëŸ‰: {traffic_type.upper()} íŠ¸ë˜í”½ ({threshold_type}) ê¸°ì¤€ "
               f"{lower_bound} < |Î´|={abs_delta:.1f} â‰¤ {upper_bound}")
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """Medium Delta ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦"""
        required_betas = ["beta_0", "beta_1", "beta_2", "beta_3"]
        for beta in required_betas:
            if config.get(beta) is None:
                self.logger.error(f"Required threshold {beta} is missing")
                return False
        return True


class HighDeltaAnalyzer(BaseKPIAnalyzer):
    """
    High Delta ë¶„ì„ê¸° (KPI ë¶„ì„ìš©)
    
    Î´ > Î²3 ì¡°ê±´ ê²€ì‚¬ (ì´ìƒ íƒì§€ì˜ High Deltaì™€ ë™ì¼í•˜ì§€ë§Œ ë‹¤ë¥¸ ì»¨í…ìŠ¤íŠ¸)
    
    Single Responsibility: High Delta ì¡°ê±´ ê²€ì‚¬ë§Œ ë‹´ë‹¹
    """
    
    def __init__(self):
        """High Delta ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        super().__init__("HighDeltaAnalyzer", AnalysisRulePriority.HIGH_DELTA)
        
        # ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©
        self.similar_analyzer = SimilarAnalyzer()
    
    def _is_rule_applicable(self, 
                           pre_stats: PegPeriodStats,
                           post_stats: PegPeriodStats,
                           compare_metrics: PegCompareMetrics,
                           config: Dict[str, Any]) -> bool:
        """High Delta ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        return (not compare_metrics.has_nd and 
                pre_stats.mean is not None and post_stats.mean is not None and
                compare_metrics.delta_pct is not None)
    
    def _execute_analysis(self, 
                         pre_stats: PegPeriodStats,
                         post_stats: PegPeriodStats,
                         compare_metrics: PegCompareMetrics,
                         config: Dict[str, Any]) -> Optional[KPIAnalysisResult]:
        """High Delta ë¶„ì„ ì‹¤í–‰"""
        try:
            beta_3 = config.get("beta_3", 500.0)
            
            # ë¸íƒ€ ê³„ì‚° (ì¬ì‚¬ìš©)
            delta_analysis = self.similar_analyzer._calculate_delta_percentage(pre_stats, post_stats)
            
            # High Delta ì¡°ê±´ ê²€ì‚¬
            abs_delta = delta_analysis["abs_delta"]
            is_high_delta = abs_delta > beta_3
            
            if is_high_delta:
                reasoning = f"ë†’ì€ ë³€í™”ëŸ‰: |Î´|={abs_delta:.1f} > Î²3({beta_3})"
                
                return KPIAnalysisResult(
                    judgement_type=JudgementType.NOK,  # High DeltaëŠ” NOK
                    compare_detail=CompareDetail.HIGH_DELTA,
                    reasoning=reasoning,
                    confidence=1.0,  # ìˆ˜í•™ì  ê³„ì‚°ì´ë¯€ë¡œ í™•ì‹¤í•¨
                    metrics=delta_analysis,
                    thresholds_used={"beta_3": beta_3}
                )
            
            return None
            
        except Exception as e:
            self.logger.error(f"High Delta analysis error: {e}")
            raise
    
    def _validate_specific_config(self, config: Dict[str, Any]) -> bool:
        """High Delta ë¶„ì„ê¸° íŠ¹í™” ì„¤ì • ê²€ì¦"""
        beta_3 = config.get("beta_3")
        if beta_3 is None:
            self.logger.error("beta_3 threshold is required")
            return False
        
        if not isinstance(beta_3, (int, float)) or beta_3 <= 0:
            self.logger.error(f"beta_3 must be a positive number, got {beta_3}")
            return False
        
        return True


# =============================================================================
# KPI ë¶„ì„ê¸° íŒ©í† ë¦¬ (Factory Pattern + Dependency Injection)
# =============================================================================

class KPIAnalyzerFactory:
    """
    KPI ë¶„ì„ê¸° íŒ©í† ë¦¬
    
    Factory Patternì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.
    ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬ëœ ë¶„ì„ê¸° ì²´ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """íŒ©í† ë¦¬ ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.logger.info("KPI analyzer factory initialized")
    
    def create_cant_judge_analyzer(self) -> CantJudgeAnalyzer:
        """Can't Judge ë¶„ì„ê¸° ìƒì„±"""
        return CantJudgeAnalyzer()
    
    def create_high_variation_analyzer(self) -> HighVariationAnalyzer:
        """High Variation ë¶„ì„ê¸° ìƒì„±"""
        return HighVariationAnalyzer()
    
    def create_improve_analyzer(self) -> ImproveAnalyzer:
        """Improve ë¶„ì„ê¸° ìƒì„±"""
        return ImproveAnalyzer()
    
    def create_degrade_analyzer(self) -> DegradeAnalyzer:
        """Degrade ë¶„ì„ê¸° ìƒì„±"""
        return DegradeAnalyzer()
    
    def create_similar_analyzer(self) -> 'SimilarAnalyzer':
        """Similar ë¶„ì„ê¸° ìƒì„±"""
        return SimilarAnalyzer()
    
    def create_low_delta_analyzer(self) -> 'LowDeltaAnalyzer':
        """Low Delta ë¶„ì„ê¸° ìƒì„±"""
        return LowDeltaAnalyzer()
    
    def create_medium_delta_analyzer(self) -> 'MediumDeltaAnalyzer':
        """Medium Delta ë¶„ì„ê¸° ìƒì„±"""
        return MediumDeltaAnalyzer()
    
    def create_high_delta_analyzer(self) -> 'HighDeltaAnalyzer':
        """High Delta ë¶„ì„ê¸° ìƒì„±"""
        return HighDeltaAnalyzer()
    
    def create_priority_ordered_analyzers(self) -> List[BaseKPIAnalyzer]:
        """
        ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ì •ë ¬ëœ ë¶„ì„ê¸° ëª©ë¡ ìƒì„±
        
        Returns:
            List[BaseKPIAnalyzer]: ìš°ì„ ìˆœìœ„ ë‚´ë¦¼ì°¨ìˆœ ë¶„ì„ê¸° ëª©ë¡
        """
        analyzers = [
            self.create_cant_judge_analyzer(),      # ìš°ì„ ìˆœìœ„ 100
            self.create_high_variation_analyzer(),  # ìš°ì„ ìˆœìœ„ 90
            self.create_improve_analyzer(),         # ìš°ì„ ìˆœìœ„ 80
            self.create_degrade_analyzer(),         # ìš°ì„ ìˆœìœ„ 80
            self.create_high_delta_analyzer(),      # ìš°ì„ ìˆœìœ„ 70
            self.create_medium_delta_analyzer(),    # ìš°ì„ ìˆœìœ„ 60
            self.create_low_delta_analyzer(),       # ìš°ì„ ìˆœìœ„ 50
            self.create_similar_analyzer()          # ìš°ì„ ìˆœìœ„ 40
        ]
        
        # ìš°ì„ ìˆœìœ„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        analyzers.sort(key=lambda x: x.get_priority(), reverse=True)
        
        self.logger.info(f"Created {len(analyzers)} analyzers in priority order")
        return analyzers
    
    def get_available_analyzers(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë¶„ì„ê¸° ëª©ë¡"""
        return ["cant_judge", "high_variation", "improve", "degrade"]




# =============================================================================
# ì´ˆê¸°í™” ë° ë¡œê¹…
# =============================================================================

logger.info("KPI analyzers module loaded successfully")
