"""
Choi íŒì • ì„œë¹„ìŠ¤ êµ¬í˜„

ì´ ëª¨ë“ˆì€ TES.web_Choi.md ë¬¸ì„œì˜ 4ì¥(ì´ìƒ íƒì§€)ê³¼ 5ì¥(í†µê³„ ë¶„ì„) 
íŒì • ì•Œê³ ë¦¬ì¦˜ì„ Strategy íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- 4ì¥: Abnormal Stats Detecting Algorithm
  - Range, New, ND, Zero, High Delta íƒì§€
  - Î±0 ê·œì¹™ì— ë”°ë¥¸ ê²°ê³¼ í‘œì‹œ ë¡œì§
- 5ì¥: Stats Analyzing Algorithm  
  - Can't Judge, High Variation, Improve/Degrade íŒì •
  - Similar/Delta ê³„ì¸µ íŒì • (Î²0-Î²5 ì„ê³„ê°’ ì ìš©)
  - Main/Sub KPI ê²°ê³¼ ì¢…í•©

PRD ì°¸ì¡°: ì„¹ì…˜ 2.2 (ì´ìƒ íƒì§€), 2.3 (í†µê³„ ë¶„ì„)
"""

import logging
import numpy as np
from typing import Dict, List, Any, Optional, Set, Tuple
from collections import defaultdict

from ..models.judgement import (
    PegSampleSeries,
    FilteringResult,
    AbnormalDetectionResult,
    MainKPIJudgement,
    PegPeriodStats,
    PegCompareMetrics,
    PegCompareDecision,
    JudgementType,
    CompareDetail,
    KPIPositivity,
    SimpleKPIJudgement
)
from ..services.strategies import BaseJudgementStrategy
from ..services.anomaly_detectors import (
    AnomalyDetectorFactory,
    AnomalyDetectionResult as DetectorResult,
    DimsDataProvider,
    MockDimsDataProvider
)
from ..services.kpi_analyzers import (
    KPIAnalyzerFactory,
    KPIAnalysisResult,
    BaseKPIAnalyzer
)

logger = logging.getLogger(__name__)


class ChoiJudgement(BaseJudgementStrategy):
    """
    Choi íŒì • ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ (4ì¥, 5ì¥)
    
    TES.web_Choi.md ë¬¸ì„œì˜ 4ì¥, 5ì¥ íŒì • ì•Œê³ ë¦¬ì¦˜ì„ ì •í™•íˆ êµ¬í˜„í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, 
                 detector_factory: Optional[AnomalyDetectorFactory] = None,
                 analyzer_factory: Optional[KPIAnalyzerFactory] = None,
                 dims_provider: Optional[DimsDataProvider] = None):
        """
        Choi íŒì • ì „ëµ ì´ˆê¸°í™”
        
        Args:
            detector_factory: ì´ìƒ íƒì§€ê¸° íŒ©í† ë¦¬ (ì˜ì¡´ì„± ì£¼ì…)
            analyzer_factory: KPI ë¶„ì„ê¸° íŒ©í† ë¦¬ (ì˜ì¡´ì„± ì£¼ì…)
            dims_provider: DIMS ë°ì´í„° ì œê³µì (ì˜ì¡´ì„± ì£¼ì…)
        """
        super().__init__("ChoiJudgement", "1.0.0")
        
        # ì˜ì¡´ì„± ì£¼ì… (Dependency Injection)
        self.dims_provider = dims_provider or MockDimsDataProvider()
        self.detector_factory = detector_factory or AnomalyDetectorFactory(self.dims_provider)
        self.analyzer_factory = analyzer_factory or KPIAnalyzerFactory()
        
        # ì´ìƒ íƒì§€ê¸°ë“¤ ì´ˆê¸°í™” (Lazy Loading)
        self._detectors = None
        
        # KPI ë¶„ì„ê¸°ë“¤ ì´ˆê¸°í™” (Lazy Loading)
        self._analyzers = None
        
        self.logger.info(f"Choi Judgement ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™” ì™„ë£Œ "
                        f"(DIMS provider: {type(self.dims_provider).__name__}, "
                        f"Factories: detector, analyzer)")
    
    def apply(self,
              filtered_data: Dict[str, List[PegSampleSeries]],
              filtering_result: FilteringResult,
              config: Dict[str, Any]) -> Dict[str, Any]:
        """
        [Algorithm Entry] íŒì • ì•Œê³ ë¦¬ì¦˜ ì „ì²´ ì‹¤í–‰
        
        4ì¥(ì´ìƒ íƒì§€)ê³¼ 5ì¥(í†µê³„ ë¶„ì„) ì•Œê³ ë¦¬ì¦˜ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¢…í•©í•©ë‹ˆë‹¤.
        
        Args:
            filtered_data: í•„í„°ë§ëœ PEG ë°ì´í„° (ê²€ì¦ ëŒ€ìƒ)
            filtering_result: í•„í„°ë§ ê²°ê³¼ (ìœ íš¨ ì‹œê°„ëŒ€ ì •ë³´ ë“±)
            config: íŒì • ì„¤ì •ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            Dict[str, Any]: ìµœì¢… íŒì • ê²°ê³¼ (abnormal_detection, kpi_judgement)
        """
        try:
            self.logger.info(f"ğŸš€ Choi íŒì • ì•Œê³ ë¦¬ì¦˜ ì‹œì‘: {len(filtered_data)}ê°œ Cell ì²˜ë¦¬")
            
            # ì…ë ¥ ê²€ì¦
            if not self.validate_input(filtered_data, filtering_result, config):
                self.logger.error("âŒ ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
                raise ValueError("Invalid input data for judgement")
            
            # 1. 4ì¥: ì´ìƒ íƒì§€ ì‹¤í–‰ (Range, New, ND, Zero, High Delta)
            self.logger.debug("ğŸ‘‰ [Step 1] 4ì¥: ì´ìƒ í†µê³„(Abnormal Stats) íƒì§€ ì‹¤í–‰")
            abnormal_detection_config = config.get("abnormal_detection", {})
            abnormal_result = self.detect_abnormal_stats(filtered_data, abnormal_detection_config)
            
            # 2. 5ì¥: KPI í†µê³„ ë¶„ì„ ì‹¤í–‰ (L2/L3 ë¶„ì„)
            self.logger.debug("ğŸ‘‰ [Step 2] 5ì¥: KPI í†µê³„ ë¶„ì„(Stats Analysis) ì‹¤í–‰")
            kpi_data = self._organize_data_by_kpi_topics(filtered_data, config.get("kpi_definitions", {}))
            stats_config = config.get("stats_analyzing", {})
            
            # KPI ë¶„ì„ê¸°ë“¤ ì´ˆê¸°í™” (Lazy Loading)
            if self._analyzers is None:
                self._analyzers = self.analyzer_factory.create_priority_ordered_analyzers()
                self.logger.debug(f"ğŸ› ï¸ KPI ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ: {len(self._analyzers)}ê°œ")
            
            kpi_judgement_result = self.analyze_kpi_stats(kpi_data, filtering_result, stats_config)
            
            # 3. ê²°ê³¼ ì¢…í•©
            result = {
                "abnormal_detection": abnormal_result,
                "kpi_judgement": kpi_judgement_result,
                "processing_metadata": {
                    "algorithm_version": self.version,
                    "processed_cells": len(filtered_data),
                    "processed_pegs": sum(len(series_list) for series_list in filtered_data.values())
                }
            }
            
            self.logger.info(f"âœ… Choi íŒì • ì•Œê³ ë¦¬ì¦˜ ì™„ë£Œ: "
                           f"ì´ìƒìœ í˜•={len(abnormal_result.model_dump())}, "
                           f"KPIí† í”½={len(kpi_judgement_result)}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ íŒì • ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", exc_info=True)
            raise RuntimeError(f"Judgement failed: {e}")
    
    def detect_abnormal_stats(self,
                             peg_data: Dict[str, List[PegSampleSeries]],
                             config: Dict[str, Any]) -> AbnormalDetectionResult:
        """
        [4ì¥] ì´ìƒ í†µê³„ íƒì§€ (Abnormal Stats Detection)
        
        Range, New, ND, Zero, High Delta ë“± í†µê³„ì  ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
        íƒì§€ í›„ Î±0 ê·œì¹™(ìµœì†Œ ì…€ ìˆ˜ ì¡°ê±´)ì„ ì ìš©í•˜ì—¬ ìµœì¢… í‘œì‹œ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            peg_data: ë¶„ì„ ëŒ€ìƒ PEG ë°ì´í„°
            config: ì´ìƒ íƒì§€ ì„¤ì • (ì„ê³„ê°’ ë“±)
            
        Returns:
            AbnormalDetectionResult: íƒì§€ëœ ì´ìƒ ê²°ê³¼ ë° í‘œì‹œ ì—¬ë¶€
        """
        try:
            self.logger.debug("ğŸ” [4ì¥] ì´ìƒ í†µê³„ íƒì§€ ì‹œì‘")
            
            # ì„¤ì •ê°’ ì¶”ì¶œ
            alpha_0 = config.get("alpha_0", 2)
            beta_3 = config.get("beta_3", 500.0)
            detection_types = config.get("detection_types", {})
            enable_range_check = config.get("enable_range_check", True)
            
            # ì´ìƒ íƒì§€ê¸°ë“¤ ì´ˆê¸°í™” (Lazy Loading)
            if self._detectors is None:
                self._detectors = self.detector_factory.create_all_detectors()
                self.logger.debug(f"ğŸ› ï¸ íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ: {len(self._detectors)}ê°œ")
            
            # ê° ì´ìƒ íƒì§€ ê·œì¹™ ì‹¤í–‰ (SOLID ì›ì¹™ ì¤€ìˆ˜)
            detection_results = {}
            
            for detector_type, detector in self._detectors.items():
                if detection_types.get(detector_type, True):
                    try:
                        # ê° íƒì§€ê¸°ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ (Single Responsibility)
                        result = detector.detect(peg_data, config)
                        detection_results[result.anomaly_type] = result
                        
                        if result.affected_cells:
                             self.logger.debug(f"âš ï¸ {detector_type} íƒì§€ë¨: {len(result.affected_cells)}ê°œ Cell")
                             
                    except Exception as e:
                        self.logger.error(f"âŒ {detector_type} íƒì§€ ì¤‘ ì˜¤ë¥˜: {e}")
                        # í•˜ë‚˜ì˜ íƒì§€ê¸° ì‹¤íŒ¨ê°€ ì „ì²´ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ (ê²¬ê³ í•œ ì˜¤ë¥˜ ì²˜ë¦¬)
                        continue
            
            # íƒì§€ ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•íƒœë¡œ ë³€í™˜
            converted_results = self._convert_detection_results(detection_results)
            
            # Î±0 ê·œì¹™ ì ìš©í•˜ì—¬ í‘œì‹œ ì—¬ë¶€ ê²°ì • (ìµœì†Œ ì…€ ìˆ˜ ë¯¸ë§Œ ì‹œ ìˆ¨ê¹€)
            display_results = self._apply_alpha_zero_rule(converted_results, alpha_0)
            
            # ê²°ê³¼ ê°ì²´ ìƒì„±
            result = AbnormalDetectionResult(
                range_violations=converted_results.get("Range", {}),
                new_statistics=converted_results.get("New", {}),
                nd_anomalies=converted_results.get("ND", {}),
                zero_anomalies=converted_results.get("Zero", {}),
                high_delta_anomalies=converted_results.get("High Delta", {}),
                display_results=display_results
            )
            
            displayed_count = sum(1 for display in display_results.values() if display)
            self.logger.info(f"âœ… ì´ìƒ íƒì§€ ì™„ë£Œ: {displayed_count}ê°œ ìœ í˜• í‘œì‹œ (Î±0 ê·œì¹™ ì ìš©ë¨)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ìƒ íƒì§€ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    def analyze_kpi_stats(self,
                          kpi_data: Dict[str, Dict[str, List[PegSampleSeries]]],
                          filtering_result: FilteringResult,
                          config: Dict[str, Any]) -> Dict[str, MainKPIJudgement]:
        """
        [5ì¥] KPI í†µê³„ ë¶„ì„ (KPI Stats Analysis)
        
        ê° KPI í† í”½(Main/Sub ê·¸ë£¹)ì— ëŒ€í•´ í†µê³„ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        1. Main/Sub ê°ê°ì— ëŒ€í•´ Î² ì„ê³„ê°’ ê¸°ë°˜ ê·œì¹™(High Variation, Improve, Degrade ë“±)ì„ ì ìš©í•©ë‹ˆë‹¤.
        2. Main KPIì™€ Sub KPIì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… íŒì •(OK/NOK/POK)ì„ ë‚´ë¦½ë‹ˆë‹¤.
        
        Args:
            kpi_data: KPI í† í”½ë³„ ë°ì´í„° ({ 'topic': {'main': [], 'subs': []} })
            filtering_result: í•„í„°ë§ ê²°ê³¼
            config: KPI ë¶„ì„ ì„¤ì • (Î² ê°’, ìš°ì„ ìˆœìœ„ ë“±)
            
        Returns:
            Dict[str, MainKPIJudgement]: í† í”½ë³„ ì¢…í•© íŒì • ê²°ê³¼
        """
        try:
            self.logger.debug("ğŸ” [5ì¥] KPI í†µê³„ ë¶„ì„ ì‹œì‘")
            
            # Î² ì„¤ì •ê°’ ì¶”ì¶œ (ê¸°ë³¸ê°’ ì„¤ì •)
            beta_values = {
                "beta_0": config.get("beta_0", 1000.0),
                "beta_1": config.get("beta_1", 5.0),
                "beta_2": config.get("beta_2", 10.0),
                "beta_3": config.get("beta_3", 500.0),
                "beta_4": config.get("beta_4", 10.0),
                "beta_5": config.get("beta_5", 3.0)
            }
            
            rule_priorities = config.get("rule_priorities", {})
            
            kpi_judgement_results = {}
            
            for topic_name, topic_data in kpi_data.items():
                self.logger.debug(f"ğŸ‘‰ í† í”½ ë¶„ì„ ì‹œì‘: {topic_name}")
                
                try:
                    # 1. Main KPI ë¶„ì„
                    main_judgement = self._analyze_main_kpi(
                        topic_data.get("main", []), 
                        beta_values, 
                        rule_priorities
                    )
                    
                    # 2. Sub KPI ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„
                    sub_data_list = topic_data.get("subs", [])
                    sub_names = topic_data.get("sub_kpi_names", [])
                    
                    sub_map = {}
                    if len(sub_data_list) == len(sub_names):
                        for name, data in zip(sub_names, sub_data_list):
                            if data:
                                sub_map[name] = data
                    
                    sub_results = self._analyze_sub_kpis(
                        sub_map,
                        beta_values,
                        rule_priorities
                    )
                    
                    # 3. ìµœì¢… ê²°ê³¼ ì¢…í•© (5.4 ê·œì¹™ ì ìš©)
                    final_judgement = self._combine_main_sub_results(
                        main_judgement, 
                        sub_results, 
                        topic_name,
                        topic_data.get("main_kpi_name", topic_name)
                    )
                    
                    if final_judgement:
                        kpi_judgement_results[topic_name] = final_judgement
                        
                except Exception as e:
                    self.logger.error(f"âŒ í† í”½ '{topic_name}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ìŠ¤í‚µ: {e}", exc_info=True)
                    continue
            
            self.logger.info(f"âœ… KPI ë¶„ì„ ì™„ë£Œ: {len(kpi_judgement_results)}ê°œ í† í”½ íŒì •ë¨")
            return kpi_judgement_results
            
        except Exception as e:
            self.logger.error(f"âŒ KPI ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    # =============================================================================
    # KPI ë¶„ì„ êµ¬í˜„ ë©”ì„œë“œë“¤ (5ì¥)
    # =============================================================================
    
    def _organize_data_by_kpi_topics(self, 
                                   filtered_data: Dict[str, List[PegSampleSeries]], 
                                   kpi_definitions: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
        """
        KPI í† í”½ë³„ ë°ì´í„° ì¬êµ¬ì„± (Data Organization)
        
        ì„¤ì •ëœ KPI ì •ì˜ì— ë”°ë¼ Main KPIì™€ Sub KPI ë°ì´í„°ë¥¼ í† í”½ ë‹¨ìœ„ë¡œ ë¬¶ìŠµë‹ˆë‹¤.
        
        Args:
            filtered_data: í•„í„°ë§ëœ PEG ë°ì´í„°
            kpi_definitions: KPI ì •ì˜ ì„¤ì • ({topic: {main: "...", subs: [...]}})
            
        Returns:
             Dict[str, Dict[str, Any]]: {'topic': {'main': [...], 'subs': [[...], ...]}} êµ¬ì¡°
        """
        organized_data = {}
        
        try:
            for topic_name, definition in kpi_definitions.items():
                # Main KPI Data ì¶”ì¶œ
                main_kpi_name = definition.get("main")
                if not main_kpi_name:
                    self.logger.warning(f"âš ï¸ í† í”½ '{topic_name}'ì— Main KPI ì •ì˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                    
                main_data = filtered_data.get(main_kpi_name, [])
                if not main_data:
                    self.logger.debug(f"â„¹ï¸ í† í”½ '{topic_name}'ì˜ Main KPI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ ({main_kpi_name})")
                
                # Sub KPI Data ì¶”ì¶œ
                sub_data_list = []
                for sub_kpi_name in definition.get("subs", []):
                    # ê° Sub KPI ë°ì´í„°ëŠ” List[PegSampleSeries] í˜•íƒœ
                    sub_data = filtered_data.get(sub_kpi_name, [])
                    sub_data_list.append(sub_data) 
                
                # Main ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ í† í”½ êµ¬ì„± (Main ê¸°ë°˜ ë¶„ì„ ì „ì œ)
                if main_data:
                    organized_data[topic_name] = {
                        "main": main_data,
                        "subs": sub_data_list,
                        "main_kpi_name": main_kpi_name,
                        "sub_kpi_names": definition.get("subs", [])
                    }
                    self.logger.debug(f"ğŸ“¦ í† í”½ êµ¬ì„± ì™„ë£Œ: {topic_name} (Sub: {len(sub_data_list)}ê°œ)")
                    
            return organized_data
            
        except Exception as e:
            self.logger.error(f"âŒ KPI ë°ì´í„° ì¬êµ¬ì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def _analyze_main_kpi(self, 
                         main_kpi_data: List[PegSampleSeries], 
                         beta_values: Dict[str, float], 
                         rule_priorities: Dict[str, int]) -> Optional[KPIAnalysisResult]:
        """Main KPI ë‹¨ì¼ ë¶„ì„ ìˆ˜í–‰"""
        if not main_kpi_data:
            return None
            
        return self._analyze_single_kpi(
            main_kpi_data, 
            main_kpi_data[0].peg_name, 
            beta_values, 
            rule_priorities
        )
    
    def _analyze_sub_kpis(self, 
                         sub_kpi_data_map: Dict[str, List[PegSampleSeries]], 
                         beta_values: Dict[str, float], 
                         rule_priorities: Dict[str, int]) -> Dict[str, KPIAnalysisResult]:
        """Sub KPI ëª©ë¡ì— ëŒ€í•œ ì¼ê´„ ë¶„ì„ ìˆ˜í–‰"""
        sub_results = {}
        
        for kpi_name, kpi_data in sub_kpi_data_map.items():
            result = self._analyze_single_kpi(
                kpi_data, 
                kpi_name, 
                beta_values, 
                rule_priorities
            )
            
            if result:
                sub_results[kpi_name] = result
                
        return sub_results

    def _analyze_single_kpi(self,
                           kpi_series_list: List[PegSampleSeries],
                           kpi_name: str,
                           beta_values: Dict[str, float],
                           rule_priorities: Dict[str, int]) -> Optional[KPIAnalysisResult]:
        """
        ë‹¨ì¼ KPI ë¶„ì„ (Single KPI Analysis)
        
        Chain of Responsibility íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë¶„ì„ê¸°(Analyzer)ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.
        ê°€ì¥ ë¨¼ì € ë§¤ì¹­ë˜ëŠ” ë¶„ì„ê¸°ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            kpi_series_list: KPI ì‹œê³„ì—´ ë°ì´í„°
            kpi_name: KPI ì´ë¦„
            beta_values: Î² ì„ê³„ê°’ë“¤
            rule_priorities: ê·œì¹™ ìš°ì„ ìˆœìœ„
            
        Returns:
            Optional[KPIAnalysisResult]: ë¶„ì„ ê²°ê³¼ (ë§¤ì¹­ëœ ê·œì¹™ì´ ì—†ìœ¼ë©´ None)
        """
        try:
            if not kpi_series_list:
                self.logger.warning(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {kpi_name}")
                return None
            
            # ì²« ë²ˆì§¸ ì‹œë¦¬ì¦ˆ ì‚¬ìš© (Main KPI ë˜ëŠ” ëŒ€í‘œ Sub KPI)
            series = kpi_series_list[0]
            
            # ê¸°ë³¸ í†µê³„ ê³„ì‚°
            pre_stats = self._calculate_period_stats(series.pre_samples)
            post_stats = self._calculate_period_stats(series.post_samples)
            compare_metrics = self._calculate_compare_metrics(pre_stats, post_stats)
            
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ë¶„ì„ê¸° ì ìš©
            analysis_config = {**beta_values, **rule_priorities}
            
            for analyzer in self._analyzers:
                try:
                    result = analyzer.analyze(pre_stats, post_stats, compare_metrics, analysis_config)
                    if result:
                        self.logger.debug(f"ğŸ“‹ {kpi_name}: '{analyzer.analyzer_name}' ê·œì¹™ ì ìš©ë¨")
                        return result
                    else:
                        pass
                except Exception as e:
                    self.logger.error(f"âŒ ë¶„ì„ê¸° '{analyzer.analyzer_name}' ì‹¤í–‰ ì˜¤ë¥˜ ({kpi_name}): {e}")
                    continue
            
            # ëª¨ë“  ë¶„ì„ê¸°ê°€ ì ìš©ë˜ì§€ ì•Šì€ ê²½ìš°
            self.logger.warning(f"âš ï¸ ë§¤ì¹­ë˜ëŠ” ë¶„ì„ ê·œì¹™ ì—†ìŒ: {kpi_name} (ê¸°ë³¸ê°’ ì‚¬ìš©)")
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ë‹¨ì¼ KPI ë¶„ì„ ì˜¤ë¥˜ ({kpi_name}): {e}", exc_info=True)
            return None
    
    def _combine_main_sub_results(self, 
                                 main_result: Optional[KPIAnalysisResult], 
                                 sub_results: Dict[str, KPIAnalysisResult],
                                 topic_name: str,
                                 main_kpi_name_arg: str) -> Optional[MainKPIJudgement]:
        """
        [í† í”½ ì¢…í•©] Main/Sub KPI ê²°ê³¼ ì¢…í•© (Topic Combination)
        
        5.4ì¥ ê·œì¹™ì„ ì ìš©í•˜ì—¬ Main KPIì™€ Sub KPIì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ì¢…í•©í•˜ê³ ,
        ìµœì¢… íŒì •(Final Decision)ì„ ë„ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            main_result: Main KPI ë¶„ì„ ê²°ê³¼
            sub_results: Sub KPI ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (kpi_name -> result)
            topic_name: í† í”½ ì´ë¦„
            main_kpi_name_arg: Main KPI ëª…
            
        Returns:
            Optional[MainKPIJudgement]: ìµœì¢… íŒì • ê²°ê³¼
        """
        try:
            if not main_result:
                self.logger.warning(f"âš ï¸ Main KPI ê²°ê³¼ ì—†ìŒ (Topic: {topic_name}) - ì¢…í•© ë¶ˆê°€")
                return None
            
            # 1. Main Resultë¥¼ SimpleKPIJudgementë¡œ ë³€í™˜ (ì²˜ë¦¬ í¸ì˜ì„±)
            main_simple = self._convert_to_simple_judgement(main_result)
            
            # 2. Sub Results ë³€í™˜ ë° ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            sub_simple_dict = {}
            sub_result_details = []
            
            for sub_name, sub_res in sub_results.items():
                sub_simple = self._convert_to_simple_judgement(sub_res)
                sub_simple_dict[sub_name] = sub_simple
                
                # ìƒì„¸ ê²°ê³¼ ì €ì¥
                sub_result_details.append({
                    "kpi_name": sub_name,
                    "judgement": sub_simple.judgement_type,
                    "detail": sub_simple.compare_detail,
                    "reason": sub_simple.reasoning,
                    "metrics": sub_simple.metrics
                })
            
            # 3. ìµœì¢… íŒì • ë¡œì§ ì ìš© (_apply_final_summary_rules í™œìš©)
            final_simple = self._apply_final_summary_rules(
                topic_name,
                main_simple,
                sub_simple_dict
            )
            
            self.logger.debug(f"ğŸ—³ï¸ í† í”½ '{topic_name}' ìµœì¢… íŒì •: {final_simple.judgement_type} "
                            f"(Main: {main_simple.judgement_type}, Sub: {len(sub_results)}ê°œ)")

            # 4. MainKPIJudgement ê°ì²´ ìƒì„± ë° ë°˜í™˜
            return MainKPIJudgement(
                main_kpi_name=main_kpi_name_arg,
                main_result=main_result.judgement_type,
                main_decision=PegCompareDecision(
                    detail=main_result.compare_detail,
                    reason=main_result.reasoning,
                    thresholds_used=main_result.thresholds_used or {},
                    confidence=main_result.confidence
                ),
                sub_results=sub_result_details,
                final_result=final_simple.judgement_type,
                summary_text=final_simple.reasoning,
                # FIXME: í†µê³„ ê°ì²´ ì§ì ‘ ì ‘ê·¼ ë¶ˆê°€ë¡œ ì¸í•œ ë¹ˆ ê°ì²´ ì‚¬ìš© (ì¶”í›„ ê°œì„  í•„ìš”)
                pre_stats=PegPeriodStats(),
                post_stats=PegPeriodStats(), 
                compare_metrics=PegCompareMetrics()
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Main/Sub ê²°ê³¼ ì¢…í•© ì¤‘ ì˜¤ë¥˜ ({topic_name}): {e}", exc_info=True)
            return None

    def _convert_to_simple_judgement(self, result: KPIAnalysisResult) -> SimpleKPIJudgement:
        """
        [Helper] KPIAnalysisResult -> SimpleKPIJudgement ë³€í™˜
        
        ë³µì¡í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½ ë¡œì§ ì²˜ë¦¬ì— ì í•©í•œ ë‹¨ìˆœ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        from app.models.judgement import SimpleKPIJudgement
        return SimpleKPIJudgement(
            judgement_type=result.judgement_type,
            compare_detail=result.compare_detail,
            reasoning=result.reasoning,
            confidence=result.confidence,
            metrics=result.metrics or {},
            thresholds_used=result.thresholds_used or {}
        )
    
    # =============================================================================
    # í†µê³„ ê³„ì‚° ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # =============================================================================
    
    # =============================================================================
    # í†µê³„ ê³„ì‚° ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # =============================================================================
    
    def _calculate_period_stats(self, samples: List[Optional[float]]) -> PegPeriodStats:
        """
        [Helper] ê¸°ê°„ë³„ í†µê³„ ê³„ì‚° (Period Statistics)
        
        ì£¼ì–´ì§„ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•œ ê¸°ë³¸ í†µê³„(í‰ê· , ìµœì†Œ, ìµœëŒ€, í‘œì¤€í¸ì°¨, NDë¹„ìœ¨, Zeroë¹„ìœ¨ ë“±)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            samples: ìƒ˜í”Œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (None í¬í•¨ ê°€ëŠ¥)
            
        Returns:
            PegPeriodStats: ê³„ì‚°ëœ í†µê³„ ê°ì²´
        """
        try:
            # None ê°’ ì œê±° (ìœ íš¨ ìƒ˜í”Œë§Œ ì¶”ì¶œ)
            valid_samples = [s for s in samples if s is not None]
            
            # ND ë° Zero ë¹„ìœ¨ ê³„ì‚°
            total_count = len(samples)
            nd_count = sum(1 for s in samples if s is None)
            nd_ratio = nd_count / total_count if total_count > 0 else 0
            
            if not valid_samples:
                # ìœ íš¨ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° (100% ND)
                return PegPeriodStats(
                    sample_count=0,
                    nd_ratio=nd_ratio,
                    zero_ratio=0.0,
                    mean=None, min=None, max=None, std=None, cv=None
                )
            
            np_samples = np.array(valid_samples)
            mean_val = float(np.mean(np_samples))
            std_val = float(np.std(np_samples))
            
            zero_count = sum(1 for s in valid_samples if s == 0.0)
            
            stats = PegPeriodStats(
                mean=mean_val,
                min=float(np.min(np_samples)),
                max=float(np.max(np_samples)),
                std=std_val,
                cv=std_val / mean_val if mean_val != 0 else None,
                nd_ratio=nd_ratio,
                zero_ratio=zero_count / len(valid_samples) if valid_samples else 0,
                sample_count=len(valid_samples)
            )
            return stats
            
        except Exception as e:
            self.logger.error(f"âŒ í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return PegPeriodStats(sample_count=0)
    
    def _calculate_compare_metrics(self, 
                                  pre_stats: PegPeriodStats, 
                                  post_stats: PegPeriodStats) -> PegCompareMetrics:
        """
        [Helper] ë¹„êµ ì§€í‘œ ê³„ì‚° (Compare Metrics)
        
        Pre ê¸°ê°„ê³¼ Post ê¸°ê°„ì˜ í†µê³„ë¥¼ ë¹„êµí•˜ì—¬ ë³€í™”ìœ¨(Delta), ND/Zero ì¡´ì¬ ì—¬ë¶€,
        íŠ¸ë˜í”½ ë³¼ë¥¨ ë“±ê¸‰ ë“±ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            pre_stats: Pre ê¸°ê°„ í†µê³„
            post_stats: Post ê¸°ê°„ í†µê³„
            
        Returns:
            PegCompareMetrics: ë¹„êµ ë¶„ì„ìš© ì§€í‘œ
        """
        try:
            # ë³€í™”ìœ¨ ê³„ì‚° ((Post - Pre) / Pre * 100)
            delta_pct = None
            if pre_stats.mean is not None and pre_stats.mean != 0:
                delta_pct = ((post_stats.mean - pre_stats.mean) / pre_stats.mean) * 100
            
            # í”Œë˜ê·¸ ì„¤ì •
            has_nd = pre_stats.nd_ratio > 0 or post_stats.nd_ratio > 0
            has_zero = pre_stats.zero_ratio > 0 or post_stats.zero_ratio > 0
            
            # íŠ¸ë˜í”½ ë³¼ë¥¨ ë¶„ë¥˜ (High/Low) - Î²0 ê¸°ì¤€
            # FIXME: beta_0 ê°’ì„ ì¸ìë¡œ ë°›ê±°ë‚˜ ì„¤ì •ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨ (í˜„ì¬ í•˜ë“œì½”ë”© 1000.0)
            beta_0 = 1000.0 
            traffic_class = "low"
            if (pre_stats.mean and pre_stats.mean >= beta_0) and (post_stats.mean and post_stats.mean >= beta_0):
                traffic_class = "high"
            
            return PegCompareMetrics(
                delta_pct=delta_pct,
                has_nd=has_nd,
                has_zero=has_zero,
                has_new=False,  # TODO: 'New' ìƒíƒœ íŒë³„ ë¡œì§ ì¶”ê°€ í•„ìš” ì—¬ë¶€ í™•ì¸
                out_of_range=False,
                traffic_volume_class=traffic_class
            )
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„êµ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return PegCompareMetrics()
    
    # =============================================================================
    # ìµœì¢… KPI ê²°ê³¼ ìš”ì•½ ë¡œì§ (PRD 2.3.5)
    # =============================================================================
    
    def summarize_final_kpi_results(self, 
                                  main_kpi_judgements: Dict[str, 'SimpleKPIJudgement'],
                                  sub_kpi_judgements: Dict[str, 'SimpleKPIJudgement']) -> Dict[str, 'SimpleKPIJudgement']:
        """
        [ìµœì¢… ìš”ì•½] ì „ì²´ KPI ê²°ê³¼ ìš”ì•½ (Result Summarization)
        
        PRD 2.3.5 ì„¹ì…˜ì˜ ê·œì¹™ì— ë”°ë¼ ê° Main KPIë³„ë¡œ ìµœì¢… íŒì •(OK/NOK/POK)ì„ ìš”ì•½í•©ë‹ˆë‹¤.
        
        ìš”ì•½ ê·œì¹™:
        1. Main NOK -> NOK
        2. Main OK + any Sub NOK -> POK (Partially OK)
        3. Main OK + all Sub OK -> OK
        4. Main Can't judge -> Can't judge
        
        Args:
            main_kpi_judgements: Main KPI íŒì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            sub_kpi_judgements: Sub KPI íŒì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            Dict[str, SimpleKPIJudgement]: ìµœì¢… ìš”ì•½ëœ KPI íŒì • ê²°ê³¼
        """
        try:
            self.logger.info("ğŸ“‘ ìµœì¢… KPI ê²°ê³¼ ìš”ì•½ ì‹œì‘")
            
            final_results = {}
            
            for main_kpi_name, main_judgement in main_kpi_judgements.items():
                
                # í•´ë‹¹ Main KPIì˜ Sub KPIë“¤ ì°¾ê¸°
                related_sub_kpis = {
                    sub_name: sub_judgement 
                    for sub_name, sub_judgement in sub_kpi_judgements.items()
                    if self._is_related_sub_kpi(main_kpi_name, sub_name)
                }
                
                # ìµœì¢… íŒì • ì ìš©
                final_judgement = self._apply_final_summary_rules(
                    main_kpi_name, main_judgement, related_sub_kpis
                )
                
                final_results[main_kpi_name] = final_judgement
                
                self.logger.debug(f"ğŸ—³ï¸ KPI '{main_kpi_name}' ìµœì¢… íŒì •: {final_judgement.judgement_type}")
            
            self.logger.info(f"âœ… ìµœì¢… KPI ê²°ê³¼ ìš”ì•½ ì™„ë£Œ: {len(final_results)}ê°œ KPI")
            return final_results
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… KPI ê²°ê³¼ ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ì›ë³¸ Main KPI ê²°ê³¼ ë°˜í™˜ (Fail-safe)
            return main_kpi_judgements
    
    def _is_related_sub_kpi(self, main_kpi_name: str, sub_kpi_name: str) -> bool:
        """
        [Helper] Sub KPIì™€ Main KPIì˜ ê´€ë ¨ì„± íŒë‹¨
        
        ë‹¨ìˆœ ì´ë¦„ ë§¤ì¹­ ê·œì¹™ì„ ì‚¬ìš©í•˜ì—¬ íŒë‹¨í•©ë‹ˆë‹¤.
        ì˜ˆ: 'Avg' ë“±ì˜ ì ‘ë¯¸ì‚¬ë¥¼ ì œê±°í•œ ê¸°ë³¸ ì´ë¦„ì´ ê°™ìœ¼ë©´ ê´€ë ¨ KPIë¡œ ê°„ì£¼.
        """
        try:
            # ì˜ˆ: AirMacDLThruAvgì™€ AirMacDLThruMaxê°€ ê´€ë ¨
            main_base = main_kpi_name.replace("Avg", "").replace("Max", "").replace("Min", "")
            sub_base = sub_kpi_name.replace("Avg", "").replace("Max", "").replace("Min", "")
            
            # ê°™ì€ ê¸°ë³¸ ì´ë¦„ì„ ê°€ì§€ë©´ ê´€ë ¨ KPIë¡œ íŒë‹¨
            is_related = main_base == sub_base and main_kpi_name != sub_kpi_name
            
            if is_related:
                # self.logger.debug(f"ğŸ”— Sub KPI '{sub_kpi_name}'ëŠ” Main KPI '{main_kpi_name}'ì™€ ê´€ë ¨ë¨")
                pass
            
            return is_related
            
        except Exception as e:
            self.logger.error(f"âŒ Sub KPI ê´€ë ¨ì„± íŒë‹¨ ì˜¤ë¥˜: {e}")
            return False
    
    def _apply_final_summary_rules(self, 
                                 main_kpi_name: str,
                                 main_judgement: 'SimpleKPIJudgement',
                                 related_sub_kpis: Dict[str, 'SimpleKPIJudgement']) -> 'SimpleKPIJudgement':
        """
        [Helper] ìµœì¢… ìš”ì•½ ê·œì¹™ ì ìš© ë¡œì§
        
        Args:
            main_kpi_name: Main KPI ì´ë¦„
            main_judgement: Main KPI íŒì • ê²°ê³¼
            related_sub_kpis: ê´€ë ¨ Sub KPI íŒì • ê²°ê³¼ë“¤
            
        Returns:
            SimpleKPIJudgement: ìµœì¢… ìš”ì•½ íŒì • ê²°ê³¼
        """
        try:
            # ê·œì¹™ 1: Main Can't judge -> Can't judge
            if main_judgement.judgement_type == JudgementType.CANT_JUDGE:
                return self._create_summary_judgement(
                    main_judgement,
                    "Main KPI íŒì • ë¶ˆê°€ë¡œ ì¸í•œ ì „ì²´ íŒì • ë¶ˆê°€",
                    related_sub_kpis,
                    "rule_1_main_cant_judge"
                )
            
            # ê·œì¹™ 2: Main NOK -> NOK
            if main_judgement.judgement_type == JudgementType.NOK:
                return self._create_summary_judgement(
                    main_judgement,
                    f"Main KPI NOK ({main_judgement.compare_detail}) â†’ ì „ì²´ NOK",
                    related_sub_kpis,
                    "rule_2_main_nok"
                )
            
            # ê·œì¹™ 3 & 4: Main OKì¸ ê²½ìš° Sub KPI ê²€í† 
            if main_judgement.judgement_type == JudgementType.OK:
                return self._evaluate_main_ok_with_subs(
                    main_kpi_name, main_judgement, related_sub_kpis
                )
            
            # ì˜ˆìƒí•˜ì§€ ëª»í•œ ê²½ìš° (ë°©ì–´ì  í”„ë¡œê·¸ë˜ë°)
            self.logger.warning(f"âš ï¸ ì˜ˆìƒí•˜ì§€ ëª»í•œ Main KPI íŒì • íƒ€ì…: {main_judgement.judgement_type}")
            return main_judgement
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… ìš”ì•½ ê·œì¹™ ì ìš© ì˜¤ë¥˜: {e}")
            return main_judgement
    
    def _evaluate_main_ok_with_subs(self, 
                                  main_kpi_name: str,
                                  main_judgement: 'SimpleKPIJudgement',
                                  related_sub_kpis: Dict[str, 'SimpleKPIJudgement']) -> 'SimpleKPIJudgement':
        """
        [Helper] Main OKì¼ ë•Œì˜ Sub KPI í‰ê°€ ë¡œì§
        
        Main KPIê°€ ì •ìƒ(OK)ì´ë¼ë„ Sub KPIì— ì´ìƒì´ ìˆìœ¼ë©´ POKë¡œ ê²©í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
        try:
            if not related_sub_kpis:
                # Sub KPIê°€ ì—†ìœ¼ë©´ Main OK ê·¸ëŒ€ë¡œ ìœ ì§€
                return self._create_summary_judgement(
                    main_judgement,
                    "Main KPI OK, Sub KPI ì—†ìŒ â†’ OK",
                    related_sub_kpis,
                    "rule_3_main_ok_no_subs"
                )
            
            # Sub KPIë“¤ì˜ íŒì • ìƒíƒœ ë¶„ì„
            sub_analysis = self._analyze_sub_kpi_results(related_sub_kpis)
            
            # ê·œì¹™ 4: Main OK + any Sub NOK -> POK (Partially OK)
            if sub_analysis["has_nok"]:
                from app.models.judgement import SimpleKPIJudgement
                pok_judgement = SimpleKPIJudgement(
                    judgement_type=JudgementType.POK,  # Partially OK
                    compare_detail=CompareDetail.PARTIALLY_OK,
                    reasoning=f"Main KPI OKì´ë‚˜ Sub KPI ì¤‘ NOK ì¡´ì¬ â†’ POK",
                    confidence=min(main_judgement.confidence, sub_analysis["min_confidence"]),
                    metrics=main_judgement.metrics,
                    thresholds_used=main_judgement.thresholds_used
                )
                
                return self._create_summary_judgement(
                    pok_judgement,
                    f"Main OK + Sub NOK({sub_analysis['nok_count']}ê°œ) â†’ POK",
                    related_sub_kpis,
                    "rule_4_main_ok_sub_nok"
                )
            
            # ê·œì¹™ 3: Main OK + all Sub OK -> OK
            return self._create_summary_judgement(
                main_judgement,
                f"Main KPI OK + ëª¨ë“  Sub KPI OK({sub_analysis['ok_count']}ê°œ) â†’ OK",
                related_sub_kpis,
                "rule_3_main_ok_all_sub_ok"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Main OK Sub í‰ê°€ ì˜¤ë¥˜: {e}")
            return main_judgement
    
    def _analyze_sub_kpi_results(self, related_sub_kpis: Dict[str, 'SimpleKPIJudgement']) -> Dict[str, Any]:
        """
        [Helper] Sub KPI ê²°ê³¼ ì§‘í•© ë¶„ì„
        
        OK/NOK/POK/Can't Judge ê°œìˆ˜ ë° ìµœì†Œ ì‹ ë¢°ë„ ë“±ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        try:
            analysis = {
                "total_count": len(related_sub_kpis),
                "ok_count": 0,
                "nok_count": 0,
                "pok_count": 0,
                "cant_judge_count": 0,
                "has_nok": False,
                "has_cant_judge": False,
                "min_confidence": 1.0,
                "nok_details": []
            }
            
            for sub_name, sub_judgement in related_sub_kpis.items():
                analysis["min_confidence"] = min(analysis["min_confidence"], sub_judgement.confidence)
                
                if sub_judgement.judgement_type == JudgementType.OK:
                    analysis["ok_count"] += 1
                elif sub_judgement.judgement_type == JudgementType.NOK:
                    analysis["nok_count"] += 1
                    analysis["has_nok"] = True
                    analysis["nok_details"].append(f"{sub_name}({sub_judgement.compare_detail})")
                elif sub_judgement.judgement_type == JudgementType.POK:
                    analysis["pok_count"] += 1
                    analysis["has_nok"] = True  # POKë„ NOKë¡œ ì·¨ê¸‰í•˜ì—¬ ìƒìœ„ POK ìœ ë°œ
                    analysis["nok_details"].append(f"{sub_name}(POK)")
                elif sub_judgement.judgement_type == JudgementType.CANT_JUDGE:
                    analysis["cant_judge_count"] += 1
                    analysis["has_cant_judge"] = True
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"Sub KPI ê²°ê³¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"total_count": 0, "has_nok": False, "has_cant_judge": False, "min_confidence": 0.5}
    
    def _create_summary_judgement(self, 
                                base_judgement: 'SimpleKPIJudgement',
                                summary_reasoning: str,
                                related_sub_kpis: Dict[str, 'SimpleKPIJudgement'],
                                rule_applied: str) -> 'SimpleKPIJudgement':
        """[Helper] ìš”ì•½ëœ íŒì • ê²°ê³¼ ê°ì²´ ìƒì„±"""
        try:
            # ê¸°ì¡´ ë©”íŠ¸ë¦­ìŠ¤ì— ìš”ì•½ ì •ë³´ ì¶”ê°€
            enhanced_metrics = {
                **base_judgement.metrics,
                "summary_rule_applied": rule_applied,
                "sub_kpi_count": len(related_sub_kpis),
                "sub_kpi_names": list(related_sub_kpis.keys()),
                "original_reasoning": base_judgement.reasoning
            }
            
            from app.models.judgement import SimpleKPIJudgement
            return SimpleKPIJudgement(
                judgement_type=base_judgement.judgement_type,
                compare_detail=base_judgement.compare_detail,
                reasoning=summary_reasoning,
                confidence=base_judgement.confidence,
                metrics=enhanced_metrics,
                thresholds_used=base_judgement.thresholds_used
            )
            
        except Exception as e:
            self.logger.error(f"ìš”ì•½ íŒì • ìƒì„± ì˜¤ë¥˜: {e}")
            return base_judgement

# =============================================================================
# ì´ˆê¸°í™” ë° ë¡œê¹…
# =============================================================================

logger.info("âœ… Choi Judgement Service ë¡œë“œ ì™„ë£Œ")
